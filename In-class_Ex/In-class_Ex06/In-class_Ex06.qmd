---
title: "In-class Exercise 6: Spatial Weights and Applications"
date: "13 February 2023"
date-modified: "`r Sys.Date()`"
number-sections: true
format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
---

## Installing and loading the R packages

```{r}
pacman::p_load(sf, sfdep, tmap, tidyverse)
```

## The data

For the purpose of this in class exercise, the Hunan data sets will be used. There are two data sets in this use case, they are:

-   Hunan, a **geospatial** data set in the ESRI shapefile format, and

-   Hunan_2012, an **attribute** dataset in csv format

### Importing geospatial data: shapefile into R environment

The code chunk below uses [*st_read()*](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import Hunan shapefile into R. The imported shapefile will be **simple features** Object of **sf**.

```{r}
hunan <- st_read(dsn = "data/geospatial", 
                 layer = "Hunan")
```

### Import csv file into r environment

Next, we will import *Hunan_2012.csv* into R by using *read_csv()* of **readr** package. The output is R dataframe class. Readr will be loaded as part of tidyverse.

```{r}
hunan2012 <- read_csv("data/aspatial/Hunan_2012.csv")
```

### Combining both data frames using left join

We want the output in an sf dataframe hence, the left dataframe should be hunan, which has a sf format. We need to find a unique identifier, in this case it is by="County", where both data frames have a common field.

```{r}
hunan_GDPPC<-hunan |> 
  left_join(hunan2012, by="County") |> 
  select(1:4, 7, 15) #selecting only the GDPPC column
```

### Plotting in a chloropleth map

```{r}
tmap_mode("plot")
tm_shape(hunan_GDPPC) +
  tm_fill("GDPPC",
          style="quantile",
          palette="Blues",
          totle="GDPPC")+
  tm_borders(alpha = 0.5) +
  tm_layout(main.title= "Distribution of GDP per capita by district", 
            main.title.position="center",
            main.title.size=1.2,
            legend.height=0.45,
            legend.width = 0.35,
            frame=TRUE)+
    tm_compass(type="8star", size=2)+
    tm_scale_bar()+
    tm_grid(alpha=0.2)
```

## Deriving Contiguity Spatial Weights

By and large, there are two types of spatial weights, they are contiguity wights and distance-based weights. In this section, you will learn how to derive contiguity spatial weights by using sfdep.

Two steps are required to derive a contiguity spatial weights, they are:

1.  identifying contiguity neighbour list by [`st_contiguity()`](https://sfdep.josiahparry.com/reference/st_contiguity.html) of **sfdep** package, and

2.  deriving the contiguity spatial weights by using [`st_weights()`](https://sfdep.josiahparry.com/reference/st_weights.html) of **sfdep** package

In this section, we will learn how to derive the contiguity neighbour list and contiguity spatial weights separately. Then, we will learn how to combine both steps into a single process.

### Identifying contiguity neighbours: Queen's method

In the code chunk below st_contiguity() is used to derive a contiguity neighbour list by using Queen's method. Note that by default, queen argument is TRUE. Rooks method will be used to identify the first order neighbour if queen=FALSE is used.

```{r}
nb_queen<-hunan_GDPPC |> 
  mutate(nb = st_contiguity(geometry), #creating nearest neighbour list
         .before=1) #put newly created field as the first column

summary(nb_queen$nb) #print the summary of the first lag neighbour list

nb_queen$County[c(2,3,4,57,85)]
```

This is just the sf version of spdep::poly2nb

### Identifying contiguity neighbours: Rooks' method

```{r}
nb_rook<-hunan_GDPPC |> 
  mutate(nb = st_contiguity(geometry, #creating nearest neighbour list
         queen=FALSE),
         .before=1) #put newly created field as the first column
```

Next, we want to Convert neighbour list to distance list

## Computing contiguity weights

### Contiguity weights: Queen's method

```{r}
wm_q <- hunan_GDPPC |> 
  mutate(nb = st_contiguity(geometry),
         wt = st_weights(nb),
         .before = 1)
```

Different from spdep, sfdep can just condense the calculation of contiguity weights into 1 line. Ie we dont have to code the previous chunk under contiguity method.

wt is a standardised weight matrics that is calculated based on 1/no of neighbours in nb list for each observation.

```{r}
wm_r <- hunan_GDPPC |> 
  mutate(nb = st_contiguity(geometry),
         queen = FALSE,
         wt = st_weights(nb),
         .before = 1)
```

### Identifying higher order neighbours

There are times that we need to identify high order contiguity neighbours. To accomplish the task, [`st_nb_lag_cumul()`](https://sfdep.josiahparry.com/reference/st_nb_lag_cumul.html) should be used as shown in the code chunk below.

```{r}
nb2_queen <-  hunan_GDPPC %>% 
  mutate(nb = st_contiguity(geometry),
         nb2 = st_nb_lag_cumul(nb, 2),
         .before = 1)
```

Note that if the order is 2, the result contains both 1st and 2nd order neighbors as shown on the print below.

```{r}
nb2_queen
```

## Deriving contiguity weights: Queen's method

Now, you are ready to compute the contiguity weights by using [`st_weights()`](https://sfdep.josiahparry.com/reference/st_weights.html) of **sfdep** package.

### Deriving contiguity weights: Queen's method

In the code chunk below, queen method is used to derive the contiguity weights.

```{r}
wm_q <- hunan_GDPPC %>%
  mutate(nb = st_contiguity(geometry),
         wt = st_weights(nb,
                         style = "W"),
         .before = 1) 
```

Notice that `st_weights()` provides tree arguments, they are:

-   *nb*: A neighbor list object as created by st_neighbors().

-   *style*: Default "W" for row standardized weights. This value can also be "B", "C", "U", "minmax", and "S". B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).

-   *allow_zero*: If TRUE, assigns zero as lagged value to zone without neighbors.

```{r}
wm_q
```

### Deriving contiguity weights: Rooks method

```{r}
wm_r <- hunan %>%
  mutate(nb = st_contiguity(geometry,
                            queen = FALSE),
         wt = st_weights(nb),
         .before = 1) 
```

## Distance-based weights

There are three popularly used distance-based spatial weights, they are:

-   fixed distance weights,

-   adaptive distance weights, and

-   inverse distance weights (IDW).

### Deriving fixed distance weights

Before we can derive the fixed distance weights, we need to determine the upper limit for distance band by using the steps below:

-   [`st_nb_dists()`](https://sfdep.josiahparry.com/reference/st_nb_dists.html) of sfdep is used to calculate the nearest neighbour distance. The output is a list of distances for each observation's neighbors list.

-   [`unlist()`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/unlist) of Base R is then used to return the output as a vector so that the summary statistics of the nearest neighbour distances can be derived.

```{r}
geo <- sf::st_geometry(hunan_GDPPC)
nb <- st_knn(geo, longlat = TRUE)
dists <- unlist(st_nb_dists(geo, nb))
```

Now, we will go ahead to derive summary statistics of the nearest neighbour distances vector (i.e. dists) by usign the coced chunk below.

```{r}
summary(dists)
```

The summary statistics report above shows that the maximum nearest neighbour distance is 65.80km. By using a threshold value of 66km will ensure that each area will have at least one neighbour.

Now we will go ahead to compute the fixed distance weights by using the code chunk below.

-   [`st_dists_band()`](https://sfdep.josiahparry.com/reference/st_dist_band.html) of sfdep is used to identify neighbors based on a distance band (i.e. 66km). The output is a list of neighbours (i.e. nb).

-   [`st_weights()`](https://sfdep.josiahparry.com/reference/st_weights.html) is then used to calculate polygon spatial weights of the nb list. Note that:

    -   the default `style` argument is set to "W" for row standardized weights, and

    -   the default `allow_zero` is set to TRUE, assigns zero as lagged value to zone without neighbors.

```{r}
wm_fd <- hunan_GDPPC %>%
  mutate(nb = st_dist_band(geometry,
                           upper = 66),
               wt = st_weights(nb),
               .before = 1)
```

## Deriving adaptive distance weights

-   [`st_knn()`](https://sfdep.josiahparry.com/reference/st_knn.html) of sfdep is used to identify neighbors based on k (i.e. k = 8 indicates the nearest eight neighbours). The output is a list of neighbours (i.e. nb).

-   [`st_weights()`](https://sfdep.josiahparry.com/reference/st_weights.html) is then used to calculate polygon spatial weights of the nb list. Note that:

    -   the default `style` argument is set to "W" for row standardized weights, and

    -   the default `allow_zero` is set to TRUE, assigns zero as lagged value to zone without neighbors.

```{r}
wm_ad <- hunan_GDPPC %>% 
  mutate(nb = st_knn(geometry,
                     k=8),
         wt = st_weights(nb),
               .before = 1)
```

## Calculate inverse distance weights

In this section, you will derive an inverse distance weights by using the code chunk below.

-   [`st_contiguity()`](https://sfdep.josiahparry.com/reference/st_contiguity.html) of sfdep is used to identify the neighbours by using contiguity criteria. The output is a list of neighbours (i.e. nb).

-   [`st_inverse_distance()`](https://sfdep.josiahparry.com/reference/st_inverse_distance.html) is then used to calculate inverse distance weights of neighbours on the nb list.

```{r}
wm_idw <- hunan_GDPPC %>%
  mutate(nb = st_contiguity(geometry),
         wts = st_inverse_distance(nb, geometry,
                                   scale = 1,
                                   alpha = 1),
         .before = 1)
```
