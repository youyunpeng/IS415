---
title: "Take-home Exercise 2"
date: "19 February 2023"
date-modified: "`r Sys.Date()`"
number-sections: true
format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
---

## Objectives

Exploratory Spatial Data Analysis (ESDA) hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate Local Indicators of Spatial Association (LISA) and Emerging Hot Spot Analysis (EHSA) to undercover the spatio-temporal trends of COVID-19 vaccination in DKI Jakarta.

## Installing Packages

```{r}
pacman::p_load(sf, sfdep, tmap, tidyverse, knitr, kableExtra)
```

## Load data

```{r}
# initialise a dataframe of our geospatial and aspatial data details
datasets <- data.frame(
  Type=c("Geospatial",
         "Aspatial"),
  Name=c("[Shapefile (SHP Batas Desa Provinsi Sumatera Barat)](https://www.indonesia-geospasial.com/2020/04/download-shapefile-shp-batas-desa.html)",
         "[Open Data Vaksinasi Provinsi DKI Jarkarta](https://riwayat-file-vaksinasi-dki-jakarta-jakartagis.hub.arcgis.com/)"),
  Format=c("Shapefile", 
           ".xlsx"),
  Description=c("Sub-districts in Indonesia",
                "Monthly vaccination Data in Jarkata")
  )

# with reference to this guide on kableExtra:
# https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html
# kable_material is the name of the kable theme
# 'hover' for to highlight row when hovering, 'scale_down' to adjust table to fit page width
library(knitr)
library(kableExtra)
kable(head(datasets), caption="Datasets Used") %>%
  kable_material("hover", latex_options="scale_down")
```

### Geospatial data

#### Reading Geospatial data into R

For the purpose of this study, DKI Jakarta administration boundary 2019 will be used. The data set can be downloaded at Indonesia Geospatial portal, specifically at [this page](https://www.indonesia-geospasial.com/2020/04/download-shapefile-shp-batas-desa.html).

```{r}
geoJAR <- st_read(dsn = "data/geospatial/",
                  layer= "BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA")
```

From the output message, we learn that:

-   Geometry type is multipolygon

-   269 features, 161 fields

-   Assigned CRS is [WGS 84](https://epsg.io/4326), the 'World Geodetic System 1984'.

#### Data Pre-Processing

We need to check for invalid geometries and missing values in our geospatial data.

```{r}
length(which(st_is_valid(geoJAR) == FALSE))
geoJAR[rowSums(is.na(geoJAR))!=0,]

geoJAR<- na.exclude(geoJAR)
```

#### Checking CRS

```{r}
st_crs(geoJAR)
```

The assigned coordinate system if WGS 84, which is not appropriate as this is an Indonesia-specific geospatial dataset. It should be using the national CRS of indonesia, GDN95, with EPSG code 23845.

```{r}
# transforms the CRS to DGN95, ESPG code 23845
geoJAR <- st_transform(geoJAR, 23845)

st_crs(geoJAR)
```

#### Removal of outer islands

As per the assignment requirements, the outer islands are not relevant to our analysis.

```{r}
# filtering out the island
geoJAR <- filter(geoJAR, KAB_KOTA != "KEPULAUAN SERIBU") # removing rows with the variable KEPULAUAN SERIBU, which translates to thousand islands
geoJAR

unique(geoJAR$KAB_KOTA) # Now we are only left with 5 unique vairbales in KAB_KOTA
```

#### Retaining the first 9 fields of geoJAR

As per the assignment requirements, we only need to retain the first 9 fields in the geoJAR table.

```{r}
# filters out other fields by accepting only the first 9 fields
geoJAR <- geoJAR[, 0:9]
```

#### Translating column names

For ease of comprehension, we translate the column names into english

```{r}
geoJAR <- geoJAR %>% 
  dplyr::rename(
    Object_ID=OBJECT_ID,
    Province=PROVINSI, 
    City=KAB_KOTA, 
    District=KECAMATAN, 
    Village_Code=KODE_DESA, 
    Village=DESA, 
    Sub_District=DESA_KELUR,
    Code=KODE, 
    Total_Population=JUMLAH_PEN
    )
```

### Aspatial Data

For the purpose of this assignment, data from [Riwayat File Vaksinasi DKI Jakarta](https://riwayat-file-vaksinasi-dki-jakarta-jakartagis.hub.arcgis.com/) will be used. Daily vaccination data are provides. We are only required to download either the first day of the month or last day of the month of the study period.

As per the assignment criteria, we downloaded vaccination data of the first day of the month from july 2021 to june 2022. For ease of reading the data into one dataframe, we rename the excel sheets to be in the following format "month year". For instance, "Data Vaksinasi Bebasis Keluarhan 1 Juli 2021).xlsx" will be renamed to "July 2021".

Now we are ready to read the excel data!

#### Reading the Aspatial Data

```{r}
# Load the readxl library
library(readxl)

# Set the working directory to the folder containing the Excel files
setwd("data/aspatial/") 

# Get a list of all Excel files in the directory
files <- list.files(pattern = ".xlsx")

# Loop through the files and read each one into a data frame
for (file in files) {
  assign(gsub(".xlsx", "", file), read_excel(file))
}
```

#### Creating a function to modify dataframes

At the end of the day, we want to create a large dataframe of all the vaccination data, categorised by the date. As part of data wrangling of our dataframes, we want to achieve the following

-   create a date column for each dataframe

-   selecting columns relating to spatial information: (\`KODE KELURAHAN\`, \`WILAYAH KOTA\`, KECAMATAN, KELURAHAN)

-   selecting columns relating to vaccination information: (\`BELUM VAKSIN\`, \`TOTAL VAKSIN\\r\\nDIBERIKAN\`)

-   translating columns to english

-   creating a new column for total population and vaccination rate

We do so by creating a function that can be used to wrangle all of the date dataframes we have in our environment.

```{r}
mutate_df<-function(data){
 df_name <- deparse(substitute(data))
 modified<-data |> 
   mutate(date=df_name,
          .before=1) |> 
   select(date, 
          `KODE KELURAHAN`, 
          `WILAYAH KOTA`, 
          KECAMATAN, 
          KELURAHAN, 
          `BELUM VAKSIN`, 
          `TOTAL VAKSIN\r\nDIBERIKAN`) |> 
   rename(village_code=`KODE KELURAHAN`, 
          city_region =`WILAYAH KOTA`, 
          subdistrict=`KECAMATAN`, 
          ward=`KELURAHAN`, 
          total_vaccination= `TOTAL VAKSIN\r\nDIBERIKAN`, 
          not_vaccinated=`BELUM VAKSIN`) |> 
  mutate(total_population=not_vaccinated+total_vaccination) |> 
  mutate(vaccination_rate=total_vaccination/total_population)
 return(modified)
}
```

We can now run all the dataframes through this function.

```{r}
July_2021<-mutate_df(`July 2021`)
August_2021<-mutate_df(`August 2021`)
September_2021<-mutate_df(`September 2021`)
October_2021<-mutate_df(`October 2021`)
November_2021<-mutate_df(`November 2021`)
December_2021<-mutate_df(`December 2021`)
January_2022<-mutate_df(`January 2022`)
February_2022<-mutate_df(`February 2022`)
March_2022<-mutate_df(`March 2022`)
April_2022<-mutate_df(`April 2022`)
May_2022<-mutate_df(`May 2022`)
June_2022<-mutate_df(`June 2022`)
```

#### Joining vaccination data

```{r}
df <- rbind(July_2021, August_2021, September_2021, October_2021, November_2021, December_2021, January_2022, February_2022, March_2022, April_2022, May_2022, June_2022) |> 
  na.exclude(TRUE) 
```

#### Preparing data for joining with geospatial data

In performing a join with the data, we can join via the village code, as both dataframes have a village code assigned to each row. Upon checking the data, we see that the unique variables in city_region field is different from the geospatial data.

```{r}
unique(df$city_region)
```

We see that there is an extra variable "KAB.ADM.KEP.SERIBU" that is present in aspatial data and not the geospatial data. We remove it using a filter function.

```{r}
df <- df|> 
   filter(city_region != "KAB.ADM.KEP.SERIBU")


unique(df$city_region) 
```

Now we are ready to join the data together!

### Combine data

To ensure that the end result is a sf dataframe, we use left_join and our sf object is placed at the left. We use st_as_sf too.

```{r}
combined_df <- left_join(df, geoJAR, by = c("village_code" = "Village_Code")) |> 
  st_as_sf()

class(combined_df)
```

For ease of plotting, we also change the class of date to a factor format.

```{r}
combined_df<- combined_df |>
  mutate(date=as.factor(date))
```

Now we are ready for Choropleth mapping!

## Chloropleth mapping

```{r}
ls<-list("July 2021", "August 2021", "September 2021", "October 2021", "November 2021", "December 2021", "January 2022", "February 2022", "March 2022", "April 2022", "May 2022", "June 2022")

```

```{r}
plot<-function(dataframe, title){
  tmap_mode("plot")
tm_shape(filter(combined_df, date %in% dataframe)) +
  tm_fill("vaccination_rate",
          n= 6,
          style = "jenks",
          palette="Blues")+
  tm_borders(alpha = 0.5) +
  tm_layout(main.title= title, 
            main.title.position="center",
            main.title.size=1.2,
            legend.height=0.45,
            legend.width = 0.35,
            frame=TRUE)+
    tm_scale_bar()+
    tm_grid(alpha=0.2)
}
plot("July 2021", "Vaccination rate in July 2021")
```

```{r}
tmap_mode("plot")
tmap_arrange(plot("July 2021", "Vaccination rate in July 2021"),
             plot("August 2021", "Vaccination rate in August 2021"),
             plot("September 2021", "Vaccination rate in September 2021"),
             plot("October 2021", "Vaccination rate in October 2021"),
             plot("November 2021", "Vaccination rate in November 2021"),
             plot("December 2021", "Vaccination rate in December 2021"),
             plot("January 2022", "Vaccination rate in January 2022"),
             plot("February 2022", "Vaccination rate in February 2022"),
             plot("March 2022", "Vaccination rate in March 2022"),
             plot("April 2022", "Vaccination rate in April 2022"),
             plot("May 2022", "Vaccination rate in May 2022"),
             plot("June 2022", "Vaccination rate in Jun3 2022"))
```

```{r, eval = FALSE}
library(shiny)
library(tmap)

date <- c("July 2021", "August 2021", "September 2021", "October 2021", "November 2021", "December 2021", "January 2022", "February 2022", "March 2022", "April 2022", "May 2022", "June 2022")

# Define the UI
ui <- fluidPage(
  selectInput(
    "date",
    label="pick a month",
    choices=date,
    selected="July 2021",
    multiple=FALSE
  ),
  # Create a tmap output element
  tmapOutput("my_map")
)

# Define the server
server <- function(input, output) {
  # Render the tmap in the output element
  output$my_map <- renderTmap({
    df<- combined_df |> 
      filter(date %in% input$date)
    # Create the tmap
    tm_shape(df) +
  tm_fill("vaccination_rate",
          style="quantile",
          palette="Blues")
  })
}

# Run the app
shinyApp(ui, server)

```

## Local Gi Analysis

Filter

```{r}
filtered<-combined_df |> 
  filter(date=="July 2021")
```

### Computing contiguity weights: Queen's method

Different from spdep, sfdep can just condense the calculation of contiguity weights into 1 line. Ie we dont have to code the previous chunk under contiguity method.

```{r}
wm_q <- filtered |> 
  mutate(nb = st_contiguity(geometry),
         wt = st_weights(nb,
                         style = "W"),
         .before = 1)
```

### Deriving fixed distance weights

```{r}
geo <- sf::st_geometry(filtered)
nb <- st_knn(geo, longlat = TRUE)
dists <- unlist(st_nb_dists(geo, nb))
```

```{r}
sum_dists<-summary(dists)
```

### Computing fixed distance weights

```{r}
wm_fd <- filtered %>%
  mutate(nb = st_dist_band(geometry,
                           upper = 3600
                             ),
               wt = st_weights(nb),
               .before = 1)
```

### Creating a function

```{r}

```

### Local Spatial Autocorrelation

### Computing local moran's I

```{r}
filtered
fips <- order(wm_fd$village_code)
localMI <- local_moran(wm_fd$vaccination_rate,
                       wm_fd$nb, 
                       wm_fd$wt)
head(localMI)
```

### Printing results in a list

```{r}
printCoefmat(data.frame(
  localMI[fips,], 
  row.names=combined_df$village_code[fips]),
  check.names=FALSE)
```

### Mapping the local Moran's I