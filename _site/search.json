[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3: Spatial Point Patterns Analysis",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#installing-and-loading-r-packages",
    "title": "Hands-on Exercise 3: Spatial Point Patterns Analysis",
    "section": "2 Installing and Loading R packages",
    "text": "2 Installing and Loading R packages\n\npacman::p_load(maptools, sf, raster, spatstat, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#spatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#spatial-data-wrangling",
    "title": "Hands-on Exercise 3: Spatial Point Patterns Analysis",
    "section": "3 Spatial Data Wrangling",
    "text": "3 Spatial Data Wrangling\nWe first use st_red() to import geospatial data into R\n\nchildcare_sf <- st_read(\"data/child-care-services-geojson.geojson\") %>%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `/Users/pengyouyun/youyunpeng/IS415/Hands-on_Ex/Hands-on_Ex03/data/child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf <- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `/Users/pengyouyun/youyunpeng/IS415/Hands-on_Ex/Hands-on_Ex03/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf <- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/pengyouyun/youyunpeng/IS415/Hands-on_Ex/Hands-on_Ex03/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nUsing the appropriate sf function you learned in Hands-on Exercise 2, retrieve the referencing system information of these geospatial data.\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nNotice that except childcare_sf, both mpsz_sf and sg_sf do not have proper crs information.\nUsing the method you learned in Lesson 2, assign the correct crs to mpsz_sf and sg_sf simple feature data frames.\n\nsg_sf<-st_transform(sg_sf, crs = 3414)\n\nmpsz_sf<-st_transform(mpsz_sf, crs = 3414)\n\nDIY: create map as given\n\ntmap_mode(\"plot\")\n\nqtm(mpsz_sf)+\nqtm(childcare_sf)\n\n\n\n\nAlternatively, we can prepare a pin map by using the code chunk below. tmap mode is set to view: interactive pin map: allows us to navigate and zoom around the map freely.\n\ntmap_mode('view')\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\nSet map mode back to plot, to avoid having an excessive number of interactive maps in one document\n\ntmap_mode('plot')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 3: Spatial Point Patterns Analysis",
    "section": "4 Geospatial Data Wrangling",
    "text": "4 Geospatial Data Wrangling\nConverting sf data frames to sp’s spatial class\n\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\nDIY: Using appropriate function, display the information of these three Spatial* classes as shown below.\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>018989</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>08F73931F4A691F4</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \nmax values  : kml_999,                  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>829646</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>RAFFLES KIDZ @ PUNGGOL PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>379D017BF244B0FA</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-spatial-class-unto-generic-sp-format",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-spatial-class-unto-generic-sp-format",
    "title": "Hands-on Exercise 3: Spatial Point Patterns Analysis",
    "section": "5 Converting the Spatial class unto generic sp format",
    "text": "5 Converting the Spatial class unto generic sp format\nspatstat requires the analytical data in ppp object form\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\n\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\n5.1 Converting the genetic sp format into spatstat’s ppp format\n\nchildcare_ppp <- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nplotting childcare_ppp\n\nplot(childcare_ppp)\n\n\n\n\nTaking a quick look at summary statistics of newly created ppp object\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNotice the warning message about duplicates. In ppp analysis, an issue of significance is the presence of duplicates. Points cannot be coincident.\n\n\n5.2 Handling duplicated points\nChecking for any duplicated objects\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of co-indicence points, we use the mutiplicity() function\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\nCounting the number of duplicated points\n\nsum(multiplicity(childcare_ppp) > 1)\n\n[1] 128\n\n\nTo view the locations of dupicated point events, plot childcare data by using code below\n\ntmap_mode('view')\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\ntmap_mode('plot')\n\nCounting duplicates: jittering, adds a small perturbation to the duplicated points so they do not occupy the exact same space\n\nchildcare_ppp_jit <- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nCheck for any duplicated point in the geospatial data\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object",
    "title": "Hands-on Exercise 3: Spatial Point Patterns Analysis",
    "section": "6 Creating owin object",
    "text": "6 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\n\nsg_owin <- as(sg_sp, \"owin\")\n\nplot(sg_owin)\n\n\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#combining-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#combining-point-events-object-and-owin-object",
    "title": "Hands-on Exercise 3: Spatial Point Patterns Analysis",
    "section": "7 Combining point events object and owin object",
    "text": "7 Combining point events object and owin object\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "title": "Hands-on Exercise 3: Spatial Point Patterns Analysis",
    "section": "8 First-order Spatial Point Patterns Analysis",
    "text": "8 First-order Spatial Point Patterns Analysis\nKernel Density Estimation: the following code chunk computes a kernel density using the following configurations of density of spatstat\n\nkde_childcareSG_bw <- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nDisplay the kernel density derived using plot()\n\nplot(kde_childcareSG_bw)\n\n\n\n\nWe realise that the density values of the output range is extremely small to comprehend. We will conduct rescaling of the KDE values in the subsequent step\nRetrieve the bandwidth used to compute kde layer using code chunk\n\nbw <- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n8.1 Rescaling KDE\nrescale() is used to convert the unit of measurement from meter to kilometer\n\nchildcareSG_ppp.km <- rescale(childcareSG_ppp, 1000, \"km\")\n\nthen, we re-run density using the rescale data set and plot output kde map\n\nkde_childcareSG.bw <- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\nDifference from earlier version: data values on the legend\n\n\n8.2 Working with different automatic bandwidth methods\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nComparing the output of using bw.diggle and bw.ppl methods\n\nkde_childcareSG.ppl <- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n8.3 Working with different kernel methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics. Computing 3 more kernel density estimations by using these 3 kernel functions\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#fixed-and-adaptive-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#fixed-and-adaptive-kde",
    "title": "Hands-on Exercise 3: Spatial Point Patterns Analysis",
    "section": "9 Fixed and Adaptive KDE",
    "text": "9 Fixed and Adaptive KDE\nCompute KDE layer by defining a bandwidth of 600 meter. Adaptive would be used when there are distinct clusters.\n\nkde_childcareSG_600 <- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n#smoother as compared to kernel \n\nComputing KDE by using adaptive bandwidth\n\nkde_childcareSG_adaptive <- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\nComparing adaptive and fixed kernel density estimation outputs\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\nConverting KDE output into grid object\n\ngridded_kde_childcareSG_bw <- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\nConverting gridded output into raster\n\nkde_childcareSG_bw_raster <- raster(gridded_kde_childcareSG_bw)\n\nLooking at properties of kde_childcareSG_bw_raster RasterLayer\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\n9.1 Assigning projection systems\n\nprojection(kde_childcareSG_bw_raster) <- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-the-output-in-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-the-output-in-tmap",
    "title": "Hands-on Exercise 3: Spatial Point Patterns Analysis",
    "section": "10 Visualising the output in tmap",
    "text": "10 Visualising the output in tmap\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#comparing-spatial-point-patterns-using-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#comparing-spatial-point-patterns-using-kde",
    "title": "Hands-on Exercise 3: Spatial Point Patterns Analysis",
    "section": "11 Comparing spatial point patterns using KDE",
    "text": "11 Comparing spatial point patterns using KDE\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\nPlotting target planning areas\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")\n\n\n\n\nConverting the spatial point data frame into generic sp format\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\nCreating owin object\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\nCombining Childcare points and the study area\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\nComputing KDE\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\nComputing fixed bandwidth KDE\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#nearest-neighbour-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#nearest-neighbour-analysis",
    "title": "Hands-on Exercise 3: Spatial Point Patterns Analysis",
    "section": "12 Nearest Neighbour Analysis",
    "text": "12 Nearest Neighbour Analysis\n\n12.1 Testing spatial point patterns using Clarks and Evans Test\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  childcareSG_ppp\nR = 0.54756, p-value = 0.01\nalternative hypothesis: clustered (R < 1)\n\n\n\n\n12.2 Clark and Evans Test: Choa Chu Kang planning area\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_ck_ppp\nR = 0.95046, p-value = 0.152\nalternative hypothesis: two-sided\n\n\n\n\n12.3 Clark and Evans Test: Tampines planning area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_tm_ppp\nR = 0.78991, p-value = 0.002\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#second-order-spatial-point-process-using-g-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#second-order-spatial-point-process-using-g-function",
    "title": "Hands-on Exercise 3: Spatial Point Patterns Analysis",
    "section": "13 Second Order Spatial Point Process Using G-Function",
    "text": "13 Second Order Spatial Point Process Using G-Function\n\n13.1 Choa Chu Kang Planning Area\nComputing G-function estimation\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n13.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-fucntion\n\nG_CK.csr <- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(G_CK.csr)\n\n\n\n\n\n\n13.3 Tampines planning area\nComputing G-function estimation\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n13.4 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nG_tm.csr <- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(G_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-f-funtion",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-f-funtion",
    "title": "Hands-on Exercise 3: Spatial Point Patterns Analysis",
    "section": "14 Analysing Spatial Point Process Using F-funtion",
    "text": "14 Analysing Spatial Point Process Using F-funtion\n\n14.1 Choa Chu Kang planning area\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n14.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-fucntion\n\nF_CK.csr <- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n14.3 Tampines planning area\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n14.4 Performing Complete Spatial Randomness Test\n\nF_tm.csr <- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-k-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-k-function",
    "title": "Hands-on Exercise 3: Spatial Point Patterns Analysis",
    "section": "15 Analysing Spatial Point Process Using K-Function",
    "text": "15 Analysing Spatial Point Process Using K-Function\nK-function measures the number of events found up to a given distance of any particular event.\n\n15.1 Choa Chu Kang Planning area\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n15.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_ck.csr <- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n15.3 Tampines Planning area\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n15.4 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_tm.csr <- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-l-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-l-function",
    "title": "Hands-on Exercise 3: Spatial Point Patterns Analysis",
    "section": "16 Analysing Spatial Point Process Using L-Function",
    "text": "16 Analysing Spatial Point Process Using L-Function\n\n16.1 Choa Chu Kang planning area\nIn graph: anything above line: clustering, below is regular\ndoes not tell us any statistical analysis: have to use envelope method through simulations\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n16.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_ck.csr <- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\nif line is within simulation: fall within 95% confidence interval, although we observe clusters, it is not statistically significant. We fail to reject the null hypothesis. To reject null hypothesis, line must be above the envelope\n\n\n16.3 Tampines planning area\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n16.4 Performing complete spatial randomness test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below will be used to perform the hypothesis testing.\n\nL_tm.csr <- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-data",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Importing data",
    "text": "Importing data\nMP14_SUBZONE_WEB_PL is in ESRI shapefile format\n\nmpsz <- st_read(dsn = \"Data/Geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/pengyouyun/youyunpeng/IS415/Hands-on_Ex/Hands-on_Ex02/Data/Geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-attribute-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-attribute-data-into-r",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Importing attribute data into R",
    "text": "Importing attribute data into R\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format\n\npopdata <- read_csv(\"Data/Aspatial/respopagesexfa2011to2020.csv\")\n\nRows: 738492 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, FA\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-wrangling",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#joining-the-attribute-data-and-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#joining-the-attribute-data-and-geospatial-data",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Joining the attribute data and geospatial data",
    "text": "Joining the attribute data and geospatial data\n\nclean data\n\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>% #converting column inputs to uppercase\n  filter(`ECONOMY ACTIVE` > 0)\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nPlease use a list of either functions or lambdas: \n\n  # Simple named list: \n  list(mean = mean, median = median)\n\n  # Auto named with `tibble::lst()`: \n  tibble::lst(mean, median)\n\n  # Using lambdas\n  list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\n\n\n\nuse left_join from dplyr to join the geographical data and attribute table through using planning subzone name as the common identifier\n\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))#left_join is used to ensure output will be a simple feature dataframe\n\nwrite_rds(mpsz_pop2020, \"Data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#chloropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#chloropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Chloropleth Mapping Geospatial Data Using tmap",
    "text": "Chloropleth Mapping Geospatial Data Using tmap\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\ntmap_mode(\"plot\") #plot option is for static map, \"view\" can be used for interactive mode\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nCreating a chloropleth map by using tmap’s elements\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nDrawing a base map\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\nUsing tm_polygons\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\") #insert selected attribute into function\n\n\n\n\nUsing tm_fill() alone, where we only created filled polygons without borders\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nAdding borders to the filled polygons previously\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nother arguments that can be used with tm_borders()\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods-of-tmap",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Data classification methods of tmap",
    "text": "Data classification methods of tmap\n\nplotting chloropleth maps with built in classification methods\n\nIn the example below, we see a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nThe below example uses equal data classification method.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\ndistribution of quantile data classification is more evenly distributed than equal data classification.\nSee the dependency bins, the intervals are more evenly distributed as compared to previous method (quantile data classification)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#customising-breaks-in-chloropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#customising-breaks-in-chloropleth-maps",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Customising breaks in chloropleth maps",
    "text": "Customising breaks in chloropleth maps\nDescriptive statistics of DEPENDENCY field to figure out what breaks we should set tm_fill to.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6540  0.7063  0.7712  0.7657 19.0000      92 \n\n\nWith reference to results, we set break points at 0.6, 0.7, 0.8, 0.9, 1.0\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#adjusting-color-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#adjusting-color-scheme",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Adjusting color scheme",
    "text": "Adjusting color scheme\nassign preferred color to palette argument of tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#changing-map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#changing-map-layouts",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Changing map layouts",
    "text": "Changing map layouts\n\nMap legend\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nmap style\n\nShowing classic style\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\""
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#other-arguments-that-can-add-different-features-to-the-map",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#other-arguments-that-can-add-different-features-to-the-map",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Other arguments that can add different features to the map",
    "text": "Other arguments that can add different features to the map\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nReset the default style\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\""
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#facet-maps",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#facet-maps",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Facet maps",
    "text": "Facet maps\nSmall multiple maps can be plotted in 3 ways\n\nassign multiple values to at least one of the aesthetic arguments\ndefining a group-by variable in tm_facets()\ncreating multiple stand-alone maps with tmap_arrage()\n\nMETHOD 1: assign multiple values to at least one of the aesthetic arguments\nexample 1: Small multiple choropleth maps are created by defining ncols in tm_fill(). filling 2 attributes in tm_fill using c() function.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\n\nexample 2: small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\nMETHOD 2: defining a group-by variable in tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\n\nMETHOD 3: Creating multiple stand alone maps with tmap_arrange()\n\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#mapping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#mapping-spatial-object-meeting-a-selection-criterion",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Mapping Spatial Object Meeting a Selection Criterion",
    "text": "Mapping Spatial Object Meeting a Selection Criterion\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on_Ex01",
    "section": "",
    "text": "In acquiring the data sets, we use commands from the sf package. Datasets acquired are allocated to variables for convenience to call out in subsequent sections. mpsz is a polygon feature data in a shapefile format, in svy21 PCS. Cyclingpath is a polyline feature in shapefile in svy21 PCS. preschool is a point feature data in kml format in wgs 84 CRS.\n\nlibrary(sf)\n\nLinking to GEOS 3.10.2, GDAL 3.4.2, PROJ 8.2.1; sf_use_s2() is TRUE\n\nmpsz <- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")#we use st_read to import a shapefile into R as a polygon feature dataframe\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/pengyouyun/youyunpeng/IS415/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\ncyclingpath <- st_read(dsn = \"data/geospatial\", layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/pengyouyun/youyunpeng/IS415/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2248 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\npreschool<-st_read(\"data/geospatial/preschools-location.kml\")#different from the previous two simple feature data frame, preschool is in wgs84 coordinates system\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/pengyouyun/youyunpeng/IS415/Hands-on_Ex/Hands-on_Ex01/data/geospatial/preschools-location.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n\nst_geometry() displays basic information of the feature class, like the type of geometry, geographic extent of the features, CRS used (SVY21). plot(mpsz) gives a multiplot of all attributes (up to 9 in this case).\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\nlibrary(tidyverse)\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.1\n✔ readr   2.1.2     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\nWe can choose to plot only the geometry by using st_geometry in plot function. In the next example, we plot a specific row of data.\n\nplot(st_geometry(mpsz))\n\n\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\nTo perform geoprocessing using 2 geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system. We can do so via projection transformation.\nwhen viewing details of mpsz sf data using st_crs(), we realise that EPSG code is 9001 instead of 3414.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWe assign the correct EPSG code to mpsz data frame using st_set_crs(). Check again that EPSG code has been changed.\n\nmpsz3414<-st_set_crs(mpsz, 3414)\n\nWarning: st_crs<- : replacing crs does not reproject data; use st_transform for\nthat\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nIt is also common for us to transform the data from geographic coordinate system to projected coordinate system. GCS is not appropriate if we want to analyse distance of conduct area measurements.\nIn this case, preschool is in GCS, WGS84. we convert it into SVY21 (PCS) using st_transform().\n\npreschool3414 <- st_transform(preschool, crs=3414)\npreschool3414\n\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11203.01 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     Name\n1   kml_1\n2   kml_2\n3   kml_3\n4   kml_4\n5   kml_5\n6   kml_6\n7   kml_7\n8   kml_8\n9   kml_9\n10 kml_10\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Description\n1             <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BRILLIANT TOTS PTE. LTD.</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9334</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>610, JURONG WEST STREET 65, #01 - 534, S 640610</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>640610</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>0523C7904478A63D</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n2             <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BUBBLESLAND PLAYHOUSE PTE LTD</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT7680</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>238, COMPASSVALE WALK, #01 - 542, S 540238</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>540238</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>18BED05A501AA168</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n3       <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BUCKET HOUSE PRESCHOOL</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9527</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>39, WOODLANDS CLOSE, #01 - 62, MEGA@WOODLANDS, S 737856</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>737856</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>C88B9AC31EE71BF6</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n4            <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BUMBLE BEE CHILD CARE CENTRE</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT3150</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>369, WOODLANDS AVENUE 1, #01 - 853, S 730369</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>730369</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>64AB8FACA8F60129</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n5               <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BUSY BEES SINGAPORE PTE LTD</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9117</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>327B, ANCHORVALE ROAD, #01 - 322, S 542327</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>542327</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>E1B55AC65B9059E8</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n6                  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BUSY BEES SINGAPORE PTE LTD</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9066</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>211A, PUNGGOL WALK, #01 - 623, S 821211</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>821211</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>3B5A4AF2696592AA</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n7       <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BUSY BEES SINGAPORE PTE LTD</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9479</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>2, GAMBAS CRESCENT,  - 01-03, NORDCOM II, S 757044</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>757044</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>5F5452B568838620</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n8          <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BUSY BEES SINGAPORE PTE.LTD</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9127</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>6, SERANGOON NORTH AVENUE 5, #02 - 01, S 554910</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>554910</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>3AD4173BBB057D89</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n9             <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>BUSY BEES SINGAPORE PTE.LTD.</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9067</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>348A, YISHUN AVENUE 11, #01 - 557, S 761348</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>761348</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>F4D7A4BDA3CBB15F</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n10 <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>CENTRE_NAME</th> <td>CAELUM JUNIOR @ BENDEMEER PTE. LTD.</td> </tr><tr bgcolor=\"\"> <th>CENTRE_CODE</th> <td>PT9053</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESS</th> <td>70, BENDEMEER ROAD, #02 - 01, LUZERNE, S 339940</td> </tr><tr bgcolor=\"\"> <th>POSTAL_CODE</th> <td>339940</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>D55FC7583E8CCBA7</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200812235534</td> </tr></table></center>\n                        geometry\n1  POINT Z (13258.34 35611.04 0)\n2  POINT Z (35272.09 41373.42 0)\n3  POINT Z (25050.54 46634.14 0)\n4  POINT Z (22892.48 46127.66 0)\n5  POINT Z (34155.79 41949.13 0)\n6   POINT Z (35414.54 42625.1 0)\n7  POINT Z (26046.98 47205.62 0)\n8  POINT Z (31980.09 39607.05 0)\n9  POINT Z (28879.22 45454.97 0)\n10 POINT Z (31250.89 33171.55 0)\n\n\n\n\n\nwhat is aspatial data? among data fields, there are 2 fields that capture the x- and y- coordinates of the data points. In this segment, we look at how to convert CSV data into an SF dataframe.\nIn the first step, we read the csv and assign it to an R object (tibble data frame)\n\nlistings <- read_csv(\"~/Desktop/Y2S2/Geospatial Analytics/Lesson 2/Hands-on_Ex01/data/aspatial/listings.csv\")\n\nRows: 6893 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (5): name, host_name, neighbourhood, room_type, license\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\nlgl   (1): neighbourhood_group\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nlist(listings)\n\n[[1]]\n# A tibble: 6,893 × 18\n      id name      host_id host_…¹ neigh…² neigh…³ latit…⁴ longi…⁵ room_…⁶ price\n   <dbl> <chr>       <dbl> <chr>   <lgl>   <chr>     <dbl>   <dbl> <chr>   <dbl>\n 1  2818 Quiet Ga…    3159 Daniel  NA      Oostel…    52.4    4.94 Privat…    49\n 2 20168 Studio w…   59484 Alexan… NA      Centru…    52.4    4.89 Privat…   106\n 3 27886 Romantic…   97647 Flip    NA      Centru…    52.4    4.89 Privat…   136\n 4 28871 Comforta…  124245 Edwin   NA      Centru…    52.4    4.89 Privat…    75\n 5 29051 Comforta…  124245 Edwin   NA      Centru…    52.4    4.89 Privat…    55\n 6 44391 Quiet 2-…  194779 Jan     NA      Centru…    52.4    4.91 Entire…   240\n 7 49552 Multatul…  225987 Joanna… NA      Centru…    52.4    4.89 Entire…   245\n 8 50523 B & B de…  231946 Raymond NA      Centru…    52.4    4.88 Privat…   124\n 9 55709 Bright L…  263233 Jan-Wi… NA      Centru…    52.4    4.90 Entire…   250\n10 55868 Apartmen…  264178 Cornel… NA      Zuid       52.4    4.89 Entire…   149\n# … with 6,883 more rows, 8 more variables: minimum_nights <dbl>,\n#   number_of_reviews <dbl>, last_review <date>, reviews_per_month <dbl>,\n#   calculated_host_listings_count <dbl>, availability_365 <dbl>,\n#   number_of_reviews_ltm <dbl>, license <chr>, and abbreviated variable names\n#   ¹​host_name, ²​neighbourhood_group, ³​neighbourhood, ⁴​latitude, ⁵​longitude,\n#   ⁶​room_type\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\nNext, we can convert the listing data frame into a SF data frame using st_as_sf().\nArguments:\n\ncoords: provide column name of x and y coordinates\ncrs: provide coordinates system in epsg format.\n\nEPSG: 4626 is wgs64 Geographic Coordinate System\nEPSG: 3414 is Singapore SVY21 Projected Coordinate System\n\n\nThen, we use st_transform() to transform SF data frame into svy21 projected coordinate system.\n\nlistings_sf<- st_as_sf(listings,\n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) |> \n  st_transform(crs = 3414)\n\nglimpse(listings_sf)\n\nRows: 6,893\nColumns: 17\n$ id                             <dbl> 2818, 20168, 27886, 28871, 29051, 44391…\n$ name                           <chr> \"Quiet Garden View Room & Super Fast Wi…\n$ host_id                        <dbl> 3159, 59484, 97647, 124245, 124245, 194…\n$ host_name                      <chr> \"Daniel\", \"Alexander\", \"Flip\", \"Edwin\",…\n$ neighbourhood_group            <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ neighbourhood                  <chr> \"Oostelijk Havengebied - Indische Buurt…\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 49, 106, 136, 75, 55, 240, 245, 124, 25…\n$ minimum_nights                 <dbl> 3, 1, 2, 2, 2, 3, 3, 2, 3, 4, 2, 3, 2, …\n$ number_of_reviews              <dbl> 305, 339, 231, 428, 582, 44, 433, 346, …\n$ last_review                    <date> 2022-08-30, 2020-04-09, 2022-04-24, 20…\n$ reviews_per_month              <dbl> 1.86, 2.22, 1.78, 2.92, 4.16, 0.30, 3.0…\n$ calculated_host_listings_count <dbl> 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 4, 1, …\n$ availability_365               <dbl> 14, 0, 121, 117, 160, 0, 165, 236, 0, 9…\n$ number_of_reviews_ltm          <dbl> 25, 0, 8, 75, 86, 3, 58, 37, 3, 0, 1, 4…\n$ license                        <chr> \"0363 5F3A 5684 6750 D14D\", \"0363 CBB3 …\n$ geometry                       <POINT [m]> POINT (-4434128 10647109), POINT …\n\n\n\n\n\nTask: In upgrading the existing cycling path, the authority needs to acquire 5 metres of reserved land on both sides of the current cycling path. You are tasked to determine the extent of land needed to be acquired and the total land area.\n\nWe use st_buffer() to compute the 5 meter buffer around cycling path\nUse st_area() to calculate area of the buffers\nUse sum() to sum all area of land\n\n\nbuffer_cycling <- st_buffer(cyclingpath, dist=5, nQuadSegs = 30)\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\n\nsum(buffer_cycling$AREA)\n\n1556978 [m^2]\n\n\nTask: pre-school service group wants to find out the number of pre-schools in each Planning Subzone.\n\nIdentify pre schools in each subzone: use st_intersects and overall 2 sfs: mpsz2414 and preschool3414 together\nCalculate the number of pre schools in each subzone: use length()\ncheck summary statistics with summary()\nList the planning subzone with the most number of pre-schools using top_n()\n\n\nmpsz3414$`PreSch Count`<-lengths(st_intersects(mpsz3414, preschool3414))\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    3.00    5.96    9.00   58.00 \n\ntop_n(mpsz3414,1,`PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           58\n\n\nTask: Calculate the density of pre-school by planning subzone\n\nUse st_area() to derive the area of each planning subzone\nuse mutate to compute the presch density (presch count/Area * 10000)\n\n\nmpsz3414$Area <- mpsz3414 |> \n  st_area()\n\nmpsz3414<-mpsz3414 |> \n  mutate(`PreSch Density` = `PreSch Count`/Area*1000000)\n\n\n\n\nPlotting a histogram to reveal the distribution of PreSch Density\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\nTo improve the quality, and move beyond the limitations of hist(), we can use ggplot functions instead.\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\nTask: use ggplot2 to plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\nWarning: Removed 2 rows containing missing values (geom_point)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415",
    "section": "",
    "text": "This is the course website of IS415 I study this term. You will find my course work on this website."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "",
    "text": "pacman::p_load(sf, tidyverse, tmap)\n\nBring data file into R\n\nNGA_wp <- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-functional-water-pumps",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-functional-water-pumps",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "2 Visualising functional water pumps",
    "text": "2 Visualising functional water pumps\n\np1<-tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n=10,\n          style=\"equal\",\n          palette=\"Blues\")+\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title= \"Distribution of functional water point by LGAs\", legend.outside = FALSE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-non-functional-water-pumps",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-non-functional-water-pumps",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "3 Visualising non-functional water pumps",
    "text": "3 Visualising non-functional water pumps\n\np2<-tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n=10,\n          style=\"equal\",\n          palette=\"Blues\")+\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title= \"Distribution of total water point by LGAs\", legend.outside = FALSE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#putting-the-two-maps-together",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#putting-the-two-maps-together",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "4 Putting the two maps together",
    "text": "4 Putting the two maps together\n\ntmap_arrange(p2, p1, nrow=1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#plotting-choropleth-map-for-rates",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#plotting-choropleth-map-for-rates",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "5 Plotting choropleth map for rates",
    "text": "5 Plotting choropleth map for rates\nMapping map rates rather than counts of things.\n\n5.1 Deriving Proportion of Functional Water Points and Non-FUnctional Water Points\n\nNGA_wp <- NGA_wp |> \n  mutate(pct_functional=wp_functional/total_wp) |> \n  mutate(pct_nonfunctional=wp_nonfunctional/total_wp)\n\n\n\n5.2 Plotting map of rate\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n=10,\n          style=\"equal\",\n          palette=\"Blues\", \n          legend.hist = TRUE)+\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title= \"Rate map of functional water point by LGAs\", legend.outside = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#extreme-value-maps",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#extreme-value-maps",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "6 Extreme value maps",
    "text": "6 Extreme value maps\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, identifying outliers.\n\n6.1 Percentile map\nspecial type of quantile map with 6 specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%.\n\n\n6.2 Data preparation\n\nexclude records with NA\n\n\nNGA_wp <- NGA_wp |> \n  drop_na()\n\n\nCreating customised classification and extracting values\n\n\npercent<- c(0, .01, .1, .5, .9, .99,1)\nvar <- NGA_wp[\"pct_functional\"] |> \n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\nCreate function to extract variable\n\n# creating a function to do whatever we did above so we can insert different objects to do the same thing\nget.var <- function(vname, df) {\n  v <- df[vname] %>%\n    st_set_geometry(NULL)\n    v <- unname(v[,1])\n  return(v)\n}\n\nPlot function\n\npercentmap <- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent <- c(0,.01,.1,.5,.9,.99,1)\n  var <- get.var(vnam, df)\n  bperc <- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"< 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"> 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n6.3 Test drive the percentile mapping function\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n6.4 Box Map\nbox map is an augmented quartile map, with an additional lower and upper category.\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n6.4.1 Creating boxbreak function\n\nboxbreaks <- function(v,mult=1.5) {\n  qv <- unname(quantile(v))\n  iqr <- qv[4] - qv[2]\n  upfence <- qv[4] + mult * iqr\n  lofence <- qv[2] - mult * iqr\n  # initialize break points vector\n  bb <- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence < qv[1]) {  # no lower outliers\n    bb[1] <- lofence\n    bb[2] <- floor(qv[1])\n  } else {\n    bb[2] <- lofence\n    bb[1] <- qv[1]\n  }\n  if (upfence > qv[5]) { # no upper outliers\n    bb[7] <- upfence\n    bb[6] <- ceiling(qv[5])\n  } else {\n    bb[6] <- upfence\n    bb[7] <- qv[5]\n  }\n  bb[3:5] <- qv[2:4]\n  return(bb)\n}\n\n\n\n\n6.5 Creating the get.var function\n\nget.var <- function(vname,df) {\n  v <- df[vname] %>% st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\n6.5.1 Test drive the newly created function\n\nvar <- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n\n6.6 Creating boxmap function\n\nboxmap <- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var <- get.var(vnam,df)\n  bb <- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"< 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"> 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)\n\n\n\n\n\n\n6.7 Recode zero\n\nNGA_wp <- NGA_wp %>%\n  mutate(wp_functional = na_if(\n    total_wp, total_wp < 0))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Excerise 4: Spatial Point Patterns Analysis",
    "section": "",
    "text": "pacman::p_load(maptools, sf, raster, spatstat, tmap)\n\nThings to learn from this code chunk\n\nchildcare_sf <- st_read(\"data/child-care-services-geojson.geojson\") %>%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `/Users/pengyouyun/youyunpeng/IS415/In-class_Ex/In-class_Ex04/data/child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nAll spatial data: use projected coordinate system instead of geographic coordinate system.\n\nsg_sf <- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `/Users/pengyouyun/youyunpeng/IS415/In-class_Ex/In-class_Ex04/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nSource is already in SVY21.\n\nmpsz_sf <- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/pengyouyun/youyunpeng/IS415/In-class_Ex/In-class_Ex04/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-map",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-map",
    "title": "In-class Excerise 4: Spatial Point Patterns Analysis",
    "section": "2 Visualising map",
    "text": "2 Visualising map\n\ntmap_mode(\"view\")\n          tm_shape(childcare_sf)+\n            tm_dots(alpha=0.5, size=0.01)+\n            tm_view(set.zoom.limits = c(11,14))# first number is the zoom out value, second number is the zoom in value ie, first number must always be smaller than the second number\n\n\n\n\n\n          #we can use tm_bubbles if we are assigning specific values to each point\n          \ntmap_mode(\"plot\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#data-wrangling-for-spatstat",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#data-wrangling-for-spatstat",
    "title": "In-class Excerise 4: Spatial Point Patterns Analysis",
    "section": "3 Data Wrangling for Spatstat",
    "text": "3 Data Wrangling for Spatstat\nspatstat: needs conversion from sf to ppp. sf–> spatial data frame–> generic spatial object–> ppp format.\n\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\nConverting spatial class into generic sp format\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\n\nConvert generic sp format into ppp format\n\nchildcare_ppp <- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nHandling duplicated point events\n\nchildcare_ppp_jit <- rjitter(childcare_ppp,\n                             retry=TRUE,\n                             nsim=1,\n                             drop=TRUE)\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Excerise 5: Advanced Spatial Point Patterns Analysis",
    "section": "",
    "text": "pacman::p_load(tidyverse, tmap, sf, sfdep)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-data",
    "title": "In-class Excerise 5: Advanced Spatial Point Patterns Analysis",
    "section": "2 Importing Data",
    "text": "2 Importing Data\n\nstudyArea<-st_read(\"data\",\n                   layer=\"study_area\") |> \n  st_transform(crs=3829)\n\nReading layer `study_area' from data source \n  `/Users/pengyouyun/youyunpeng/IS415/In-class_Ex/In-class_Ex05/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 7 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 121.4836 ymin: 25.00776 xmax: 121.592 ymax: 25.09288\nGeodetic CRS:  TWD97\n\nstores<-st_read(\"data\",\n                   layer=\"stores\") |> \n  st_transform(crs=3829)\n\nReading layer `stores' from data source \n  `/Users/pengyouyun/youyunpeng/IS415/In-class_Ex/In-class_Ex05/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1409 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 121.4902 ymin: 25.01257 xmax: 121.5874 ymax: 25.08557\nGeodetic CRS:  TWD97\n\n\nVisualising the sf layers\n\ntmap_mode(\"view\")\ntm_shape(studyArea)+ #always display polygons before points\n  tm_polygons()+\n  tm_shape(stores)+\n  tm_dots(col=\"Name\",\n           size=0.01,\n           border.col=\"black\",\n           border.lwd=0.5)+\n  tm_view(set.zoom.limits = c(12,16))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#local-colocation-coefficient",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#local-colocation-coefficient",
    "title": "In-class Excerise 5: Advanced Spatial Point Patterns Analysis",
    "section": "3 Local Colocation coefficient",
    "text": "3 Local Colocation coefficient\nfor colocation coefficient\n\ncharacter or factor vector\nneighbour list\n\n\nnb<-include_self(\n  st_knn(st_geometry(stores), 6)# search for 6 nearest neighbours, using adaptive method, to always use even number, since we include self, always get one group to be more than another\n)\n\nwt<-st_kernel_weights(nb,\n                      stores,\n                      \"gaussian\",\n                      adaptive=TRUE) #convert into a weight metrics, see table, under column value: shows the distance weight allocated for each neighbour\n\nFamilyMart<-stores |> \n  filter(Name == \"Family Mart\")\nA<- FamilyMart$Name\n\nSevenEleven<-stores |> \n  filter(Name == \"7-Eleven\")\nB<- SevenEleven$Name\n\nLCLQ<-local_colocation(A, B, nb, wt, 49) #A is my target, B is the neighbour im interested in, nb is nearest neighbour list, wt is the weight. We would immediately get p value from this\n\n#NA means cannot find any useful index to work with\n\nLCLQ_stores<-cbind(stores,LCLQ) # inorder to map data, we have to comnbine the stores and colocation values. we put stores as the first one, as we want to keep the geometric properties in the object\n\n\n# dont have unique identifier, ie cannot use left join or right join\n\ntmap_mode(\"view\")\ntm_shape(studyArea) +\n  tm_polygons() + \ntm_shape(LCLQ_stores) +\n  tm_dots(col = \"X7.Eleven\",\n          size = 0.01,\n          border.col=\"black\",\n           border.lwd=0.5)+\n  tm_view(set.zoom.limits = c(12,16))\n\n\n\n\n\n#able to visualise the colocation points/isolated points \n\nst_knn: identifies the k nearest neighbors for given point geometry"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/data/study_area.html",
    "href": "In-class_Ex/In-class_Ex05/data/study_area.html",
    "title": "IS415",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/data/stores.html",
    "href": "In-class_Ex/In-class_Ex05/data/stores.html",
    "title": "IS415",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class_Ex02",
    "section": "",
    "text": "pacman::p_load(sf, tidyverse, funModeling)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#geoboundaries-data-set",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#geoboundaries-data-set",
    "title": "In-class_Ex02",
    "section": "GeoBoundaries data set",
    "text": "GeoBoundaries data set\n\ngeoNGA <- st_read(\"data/geospatial/\", layer = \"geoBoundaries-NGA-ADM2\") |>  \nst_transform(crs = 26392)\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `/Users/pengyouyun/youyunpeng/IS415/In-class_Ex/In-class_Ex02/Data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#the-nga-data-set",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#the-nga-data-set",
    "title": "In-class_Ex02",
    "section": "The NGA data set",
    "text": "The NGA data set\n\nNGA <- st_read(\"Data/geospatial/\",\n               layer = \"nga_admbnda_adm2_osgof_20190417\") %>%\n  st_transform(crs = 26392)\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `/Users/pengyouyun/youyunpeng/IS415/In-class_Ex/In-class_Ex02/Data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-aspatial-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-aspatial-data",
    "title": "In-class_Ex02",
    "section": "Importing Aspatial data",
    "text": "Importing Aspatial data\n\npacman::p_load(sf, tidyverse, funModeling)\nwp_nga <- read_csv(\"data/aspatial/WPdx.csv\") %>%\n  filter(`#clean_country_name` == \"Nigeria\")\n\nWarning: One or more parsing issues, see `problems()` for details\n\n\nRows: 406566 Columns: 70\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (43): #source, #report_date, #status_id, #water_source_clean, #water_sou...\ndbl (23): row_id, #lat_deg, #lon_deg, #install_year, #fecal_coliform_value, ...\nlgl  (4): #rehab_year, #rehabilitator, is_urban, latest_record\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#converting-water-point-data-into-sf-point-features",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#converting-water-point-data-into-sf-point-features",
    "title": "In-class_Ex02",
    "section": "Converting water point data into sf point features",
    "text": "Converting water point data into sf point features\nif the dataframe has long and latt, use st_as_sf, and put coords = c(“long”, “latt”) to convert to sf object\n\nwp_nga$Geometry = st_as_sfc(wp_nga$`New Georeferenced Column`)\nwp_nga\n\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\nwp_sf <-  st_sf(wp_nga, crs=4326) #convert to sf, tell R what crs used for projection \nwp_sf\n\nSimple feature collection with 95008 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2.707441 ymin: 4.301812 xmax: 14.21828 ymax: 13.86568\nGeodetic CRS:  WGS 84\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#projection-transformation",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#projection-transformation",
    "title": "In-class_Ex02",
    "section": "Projection Transformation",
    "text": "Projection Transformation"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#converting-aspatial-data-into-geospatial",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#converting-aspatial-data-into-geospatial",
    "title": "In-class_Ex02",
    "section": "Converting Aspatial Data into Geospatial",
    "text": "Converting Aspatial Data into Geospatial\n\nwp_nga$Geometry = st_as_sfc(wp_nga$`New Georeferenced Column`)\n\nwp_nga\n\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\nwp_sf<-st_sf(wp_nga, crs=4326)\nwp_sf\n\nSimple feature collection with 95008 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2.707441 ymin: 4.301812 xmax: 14.21828 ymax: 13.86568\nGeodetic CRS:  WGS 84\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#projection-transformation-1",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#projection-transformation-1",
    "title": "In-class_Ex02",
    "section": "Projection transformation",
    "text": "Projection transformation\n\nwp_sf <- wp_sf %>%\n  st_transform(crs = 26392)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#excluding-redundant-fields",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#excluding-redundant-fields",
    "title": "In-class_Ex02",
    "section": "Excluding redundant fields",
    "text": "Excluding redundant fields\n\nNGA<- NGA |> \n  select(c(3:4, 8:9))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#checking-for-duplicate-name",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#checking-for-duplicate-name",
    "title": "In-class_Ex02",
    "section": "Checking for duplicate name",
    "text": "Checking for duplicate name\n\nNGA$ADM2_EN[duplicated(NGA$ADM2_EN)==TRUE]\n\n[1] \"Bassa\"    \"Ifelodun\" \"Irepodun\" \"Nasarawa\" \"Obi\"      \"Surulere\"\n\n\n\n# Get all the duplicated LGA names\nduplicated_LGA <- NGA$ADM2_EN[duplicated(NGA$ADM2_EN)==TRUE]\n\n# Get all the indices with names that are included in the duplicated LGA names\nduplicated_indices <- which(NGA$ADM2_EN %in% duplicated_LGA)\n\n# For every index in the duplicated_indices, concatenate the two columns with a comma\nfor (ind in duplicated_indices) {\n  NGA$ADM2_EN[ind] <- paste(NGA$ADM2_EN[ind], NGA$ADM1_EN[ind], sep=\", \")\n}"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#data-wrangling",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#data-wrangling",
    "title": "In-class_Ex02",
    "section": "Data wrangling",
    "text": "Data wrangling\n\nwp_sf_nga <- wp_sf |> \n  rename(status_clean = '#status_clean') |> \n  select(status_clean) |> \n  mutate(status_clean = replace_na(\n    status_clean, \"unknown\"\n  ))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#extracting-water-point-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#extracting-water-point-data",
    "title": "In-class_Ex02",
    "section": "Extracting water point data",
    "text": "Extracting water point data\n\nwp_functional <- wp_sf_nga |> \n  filter(status_clean %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\nThe code chunk below is used to extract nonfunctional waterpoint\n\nwp_nonfunctional <- wp_sf_nga |> \n  filter(status_clean %in% \n           c(\"Abandoned/Decommissioned\",\n             \"Abandoned\",\n             \"Non-Functional due to dry season\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\"))\n\n\nwp_unknown <- wp_sf_nga |> \n  filter(status_clean %in% \n           c(\"unknown\"))\n\n\nNGA_wp <- NGA %>%   \n  mutate(`total_wp` = lengths(\n    st_intersects(NGA, wp_sf_nga))) %>%   \n  mutate(`wp_functional` = lengths(     \n    st_intersects(NGA, wp_functional))) %>%   \n  mutate(`wp_nonfunctional` = lengths(     \n    st_intersects(NGA, wp_nonfunctional))) %>%   \n  mutate(`wp_unknown` = lengths(     \n    st_intersects(NGA, wp_unknown)))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#saving-the-analytical-data-in-rds-format",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#saving-the-analytical-data-in-rds-format",
    "title": "In-class_Ex02",
    "section": "Saving the analytical data in rds format",
    "text": "Saving the analytical data in rds format\n\nwrite_rds(NGA_wp, \"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "In this take home exercise, we are tasked to apply appropriate spatial point pattern analysus methods to discover the geographical distribution of functional and non-functional waterpoints and their colocations if any in Osun state, Nigeria.\nThe main tasks of this exercise includes\n\nExploratory Spatial Data Analaysis\nSecond-order Spatial Point Pattern Analysis\nSpatial Correlation Analysis\n\n\n\nWe first start off by loading the necessary R packages into our platform.\n\npacman::p_load(maptools, sf, raster, spatstat, tmap, tidyverse, funModeling, sfdep)\n\n\n\n\n\n\nThis study will focus of Osun State, Nigeria. The state boundary GIS data of Nigeria can be downloaded from geoBoundaries.\n\n\nWithin the geoboundaries data, we choose to use ADM2 data given that we want to investigate the distribution of water pumps within the LGAs in Osun.\n\ngeoNGA2 <- st_read(dsn = \"data/geospatial\", layer = \"nga_admbnda_adm2_osgof_20190417\") |>  st_transform(crs = 26392) |> \n  arrange(ADM2_EN)\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `/Users/pengyouyun/youyunpeng/IS415/Take-home_Ex/Take-home_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n#check for duplicates\ngeoNGA2$ADM2_EN[duplicated(geoNGA2$ADM2_EN) == TRUE]\n\n[1] \"Bassa\"    \"Ifelodun\" \"Irepodun\" \"Nasarawa\" \"Obi\"      \"Surulere\"\n\nduplicated_LGA <- geoNGA2$ADM2_EN[duplicated(geoNGA2$ADM2_EN) == TRUE]\n# Get all the indices with names that are included in the duplicated LGA names\nduplicated_indices <- which(geoNGA2$ADM2_EN %in% duplicated_LGA)\n\ngeoNGA2$ADM2_EN[94] <- \"Bassa, Kogi\"\ngeoNGA2$ADM2_EN[95] <- \"Bassa, Plateau\"\ngeoNGA2$ADM2_EN[304] <- \"Ifelodun, Kwara\"\ngeoNGA2$ADM2_EN[305] <- \"Ifelodun, Osun\"\ngeoNGA2$ADM2_EN[355] <- \"Irepodun, Kwara\"\ngeoNGA2$ADM2_EN[356] <- \"Irepodun, Osun\"\ngeoNGA2$ADM2_EN[519] <- \"Nasarawa, Kano\"\ngeoNGA2$ADM2_EN[520] <- \"Nasarawa, Nasarawa\"\ngeoNGA2$ADM2_EN[546] <- \"Obi, Benue\"\ngeoNGA2$ADM2_EN[547] <- \"Obi, Nasarawa\"\ngeoNGA2$ADM2_EN[693] <- \"Surulere, Lagos\"\ngeoNGA2$ADM2_EN[694] <- \"Surulere, Oyo\"\n\nThe code chunk below filters out geoNGA2 into Osun state Local Government Area\n\nosun_LGA <- c(\"Aiyedade\",\"Aiyedire\",\"Atakumosa East\",   \"Atakumosa West\",   \n              \"Ede North\",  \"Ede South\",    \"Egbedore\", \"Ejigbo\",   \"Ife Central\",  \n              \"Ife East\",   \"Ife North\",    \"Ife South\",    \"Ifedayo\",  \"Ila\",\n              \"Ifelodun, Osun\",\"Irepodun, Osun\",\"Ilesha East\",  \"Ilesha West\",\n              \"Irewole\",    \"Isokan\",   \"Iwo\",  \"Obokun\",   \"Odo-Otin\", \"Ola-oluwa\",    \n              \"Olorunda\",   \"Oriade\",   \"Orolu\",    \"Osogbo\", \"Boripe\", \"Boluwaduro\")\n\nbd <- geoNGA2 |> \n  filter(ADM2_EN %in% osun_LGA) #create border sf that filters out Osun LGAs\n\nqtm(bd) #checking if the border data is correctly filtered\n\n\n\n\n\n\n\n\nFor the purpose of this assignment, data from WPdx Global Data Repositories will be used.\n\n\nAgain, in the waterpoint data can be narrowed down to only osun state.\n\nwp_osun <- read_csv(\"data/aspatial/WPdx.csv\") %>%\n  filter(`#clean_country_name` == \"Nigeria\", `#clean_adm1`==\"Osun\")\n\nWith our packages and data in place, we can now start with our analysis!"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#bringing-data-into-platform",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#bringing-data-into-platform",
    "title": "Take-home Exercise 1",
    "section": "2 Bringing data into platform",
    "text": "2 Bringing data into platform\n\n2.1 Apstial data\nFor the purpose of this assignment, data from WPdx Global Data Repositories will be used. There are two versions of the data. They are: WPdx-Basic and WPdx+. You are required to use WPdx+ data set.\n\n\n2.2 Geospatial data\nThis study will focus of Osun State, Nigeria. The state boundary GIS data of Nigeria can be downloaded either from The Humanitarian Data Exchange portal or geoBoundaries.\n\n2.2.1 Reading geospatial data\nWithin the geoboundaries data, we choose to use ADM1 data given that we want to isolate a specific state.\n\ngeoNGA1 <- st_read(\"data/geospatial/\", layer = \"geoBoundaries-NGA-ADM1\") |>  \nst_transform(crs = 26392)\n\nReading layer `geoBoundaries-NGA-ADM1' from data source \n  `/Users/pengyouyun/youyunpeng/IS415/Take-home_Ex/Take-home_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 37 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.692613 ymin: 4.271484 xmax: 14.67797 ymax: 13.88571\nGeodetic CRS:  WGS 84\n\nbd<-geoNGA1 |> \n  filter(shapeName == \"Osun\")\n\nst_crs(bd)#checking the crs of bd\n\nCoordinate Reference System:\n  User input: EPSG:26392 \n  wkt:\nPROJCRS[\"Minna / Nigeria Mid Belt\",\n    BASEGEOGCRS[\"Minna\",\n        DATUM[\"Minna\",\n            ELLIPSOID[\"Clarke 1880 (RGS)\",6378249.145,293.465,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4263]],\n    CONVERSION[\"Nigeria Mid Belt\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",4,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",8.5,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.99975,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",670553.98,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Nigeria between 6°30'E and 10°30'E, onshore and offshore shelf.\"],\n        BBOX[3.57,6.5,13.53,10.51]],\n    ID[\"EPSG\",26392]]\n\nplot(bd)#plotting the border of Osun state\n\n\n\n\n\n\n2.2.2 Reading aspatial data\nAgain, in the waterpoint data can be narrowed down to only osun state.\n\nwp_osun <- read_csv(\"data/aspatial/WPdx.csv\") %>%\n  filter(`#clean_country_name` == \"Nigeria\", `#clean_adm1`==\"Osun\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-water-point-data-into-sf-point-features",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-water-point-data-into-sf-point-features",
    "title": "Take-home Exercise 1",
    "section": "3 Converting water point data into sf point features",
    "text": "3 Converting water point data into sf point features\nFirst we need to convert the wkt field into sfc field by using st_as_sfc() data type. Next we will convert the tibble data.frame into an sf object by isomh st_sf(). it is also important for us to include the referencing system of the data into the sf object. In this case, it has the CRS of WGS 84, so we set the crs to EPSG code 4326.\n\nwp_osun$Geometry = st_as_sfc(wp_osun$`New Georeferenced Column`)\nwp_osun\n\n# A tibble: 5,557 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429123 GRID3             8.02    5.06 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2  70566 Federal Minis…    7.32    4.79 05/11/… No      Protec… Well    Mechan…\n 3  70578 Federal Minis…    7.76    4.56 05/11/… No      Boreho… Well    Mechan…\n 4  66401 Federal Minis…    8.03    4.64 04/30/… No      Boreho… Well    Mechan…\n 5 422190 GRID3             7.87    4.88 08/29/… Unknown <NA>    <NA>    Tapsta…\n 6 422064 GRID3             7.7     4.89 08/29/… Unknown <NA>    <NA>    Tapsta…\n 7  65607 Federal Minis…    7.89    4.71 05/12/… No      Boreho… Well    Mechan…\n 8  68989 Federal Minis…    7.51    4.27 05/07/… No      Boreho… Well    <NA>   \n 9  67708 Federal Minis…    7.48    4.35 04/29/… Yes     Boreho… Well    Mechan…\n10  66419 Federal Minis…    7.63    4.50 05/08/… Yes     Boreho… Well    Hand P…\n# … with 5,547 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\nwp_sf <-  st_sf(wp_osun, crs=4326) #convert to sf, tell R what crs used for projection \nwp_sf\n\nSimple feature collection with 5557 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 4.032004 ymin: 7.060309 xmax: 5.06 ymax: 8.061898\nGeodetic CRS:  WGS 84\n# A tibble: 5,557 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429123 GRID3             8.02    5.06 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2  70566 Federal Minis…    7.32    4.79 05/11/… No      Protec… Well    Mechan…\n 3  70578 Federal Minis…    7.76    4.56 05/11/… No      Boreho… Well    Mechan…\n 4  66401 Federal Minis…    8.03    4.64 04/30/… No      Boreho… Well    Mechan…\n 5 422190 GRID3             7.87    4.88 08/29/… Unknown <NA>    <NA>    Tapsta…\n 6 422064 GRID3             7.7     4.89 08/29/… Unknown <NA>    <NA>    Tapsta…\n 7  65607 Federal Minis…    7.89    4.71 05/12/… No      Boreho… Well    Mechan…\n 8  68989 Federal Minis…    7.51    4.27 05/07/… No      Boreho… Well    <NA>   \n 9  67708 Federal Minis…    7.48    4.35 04/29/… Yes     Boreho… Well    Mechan…\n10  66419 Federal Minis…    7.63    4.50 05/08/… Yes     Boreho… Well    Hand P…\n# … with 5,547 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\nHowever, we want to convert the coordinate reference system to Nigeria’s projected coordinate system. We use st_transform(), and include the EPSG code for Nigeria’s projected coordinate system: 26392.\n\nwp_sf <- wp_sf %>%\n  st_transform(crs = 26392)\n\nqtm(wp_sf) #quick view"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling-for-waterpoint-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling-for-waterpoint-data",
    "title": "Take-home Exercise 1",
    "section": "4 Data wrangling for waterpoint data",
    "text": "4 Data wrangling for waterpoint data\nIn cleaning the waterpoint data, we first rename the column from #status_clean to status_clean for easier handling in subsequent steps. select() of dplyr is used to include status_clean in the output sf data.frame. - mutate() and replace_na() are used to recode all the NA values in status_clean into unknown.\n\nwp_sf_nga <- wp_sf |> \n  rename(status_clean = '#status_clean') |> \n  select(status_clean) |> \n  mutate(status_clean = replace_na(\n    status_clean, \"unknown\"\n  ))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extracting-water-point-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extracting-water-point-data",
    "title": "Take-home Exercise 1",
    "section": "5 Extracting water point data",
    "text": "5 Extracting water point data\nNow we are ready to extract the water point data according to their status.\nThe code chunk below is used to extract functional water points.\n\nwp_functional <- wp_sf_nga |> \n  filter(status_clean %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\nThe code chunk below is used to extract nonfunctional waterpoint.\n\nwp_nonfunctional <- wp_sf_nga |> \n  filter(status_clean %in% \n           c(\"Abandoned/Decommissioned\",\n             \"Abandoned\",\n             \"Non-Functional due to dry season\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\"))\n\nThe code chunk below is used to extract water point with unknown status.\n\nwp_unknown <- wp_sf_nga |> \n  filter(status_clean %in% \n           c(\"unknown\"))\n\nNext, the code chunk below is used to perform a quick EDA on the derived sf data.frames.\n\nfreq(data = wp_functional,\n     input = 'status_clean')\n\n\n\n\n                 status_clean frequency percentage cumulative_perc\n1                  Functional      2319      88.17           88.17\n2 Functional but needs repair       248       9.43           97.60\n3   Functional but not in use        63       2.40          100.00\n\n\n\nfreq(data = wp_nonfunctional,\n     input = 'status_clean')\n\n\n\n\n                      status_clean frequency percentage cumulative_perc\n1                   Non-Functional      2008      92.15           92.15\n2 Non-Functional due to dry season       151       6.93           99.08\n3                        Abandoned        15       0.69           99.77\n4         Abandoned/Decommissioned         5       0.23          100.00"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling-to-prepare-data-for-spatstat",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling-to-prepare-data-for-spatstat",
    "title": "Take-home Exercise 1",
    "section": "2.2 Data Wrangling to Prepare Data for Spatstat",
    "text": "2.2 Data Wrangling to Prepare Data for Spatstat\n\n2.2.1 Converting sf data frames to sp’s Spatial Class\nThe code chunk below uses as_Spatial(). of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nNGA_bd_sc<-as(bd, \"Spatial\")\nNGA_bd_sc\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 30 \nextent      : 176503.2, 291043.8, 331434.7, 454520.1  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 16\nnames       :    Shape_Leng,       Shape_Area,  ADM2_EN, ADM2_PCODE, ADM2_REF, ADM2ALT1EN, ADM2ALT2EN, ADM1_EN, ADM1_PCODE, ADM0_EN, ADM0_PCODE,  date, validOn, validTo,        SD_EN, ... \nmin values  : 0.26445678806, 0.00248649736648, Aiyedade,   NG030001, Aiyedade,         NA,         NA,    Osun,      NG030, Nigeria,         NG, 17134,   18003,      NA, Osun Central, ... \nmax values  :  1.8470166597,  0.0737271661922,   Osogbo,   NG030030,   Osogbo,         NA,         NA,    Osun,      NG030, Nigeria,         NG, 17134,   18003,      NA,    Osun West, ... \n\nfunc<-as(wp_functional, \"Spatial\")\nfunc\n\nclass       : SpatialPointsDataFrame \nfeatures    : 2630 \nextent      : 177285.9, 290751, 343128.1, 450859.7  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 1\nnames       :              status_clean \nmin values  :                Functional \nmax values  : Functional but not in use \n\nnonfunc<-as(wp_nonfunctional, \"Spatial\")\nnonfunc\n\nclass       : SpatialPointsDataFrame \nfeatures    : 2179 \nextent      : 180539, 290616, 340054.1, 450780.1  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 1\nnames       :                     status_clean \nmin values  :                        Abandoned \nmax values  : Non-Functional due to dry season \n\n\n\n\n2.2.2 Converting the Spatial* class into generic sp format\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\nThe codes chunk below converts the Spatial* classes into generic sp objects.\n\nNGA_bd_sp <- as(NGA_bd_sc, \"SpatialPolygons\")\n\nfuncsp<-as(func, \"SpatialPoints\")\nnonfuncsp<-as(nonfunc, \"SpatialPoints\")\n\n\n\n2.2.3 Convert generic sp format into spatstat’s ppp format\n\nfuncppp<-as(funcsp, \"ppp\")\nnonfuncppp<-as(nonfuncsp,\"ppp\")\n\n\n\n2.2.4 Checking for Duplicated Points\nWe can check for the duplication in a ppp object by using the code chunk below. We see that there are no duplicated points.\n\nany(duplicated(funcppp))\n\n[1] FALSE\n\nany(duplicated(nonfuncppp))\n\n[1] FALSE\n\n\n\n\n2.2.5 Creating Owin Object\nTo confine our analysis with the geographical area Osun, we create an object called owin in spatstat to represent the polygonal region.\nThe code chunk below is used to convert NGA_bd_sp into owin object of spatstat.\n\nNGA_owin<- as(NGA_bd_sp, \"owin\")\n\n\n\n2.2.6 Combine point events object and owin object\nIn this last step of geospatial data wrangling, we will extract the waterpoints that are located within Osun by using the code chunk below.\n\n#funcppp\nfuncppp1<-funcppp[NGA_owin]\nsummary(funcppp1)\n\nPlanar point pattern:  2529 points\nAverage intensity 2.928471e-07 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: polygonal boundary\n30 separate polygons (no holes)\n            vertices      area relative.area\npolygon 1        204 766084000       0.08870\npolygon 2         81 304399000       0.03520\npolygon 3         97 465688000       0.05390\npolygon 4        124 373051000       0.04320\npolygon 5         60 149473000       0.01730\npolygon 6         84 144820000       0.01680\npolygon 7         50 102243000       0.01180\npolygon 8         72 216002000       0.02500\npolygon 9        112 269897000       0.03130\npolygon 10       125 365142000       0.04230\npolygon 11        83 111191000       0.01290\npolygon 12       126 192557000       0.02230\npolygon 13       219 904397000       0.10500\npolygon 14       174 741131000       0.08580\npolygon 15        81 138742000       0.01610\npolygon 16        65 119452000       0.01380\npolygon 17        90 280205000       0.03240\npolygon 18        69  69814600       0.00808\npolygon 19        69  42727500       0.00495\npolygon 20        49  30458800       0.00353\npolygon 21        62 263505000       0.03050\npolygon 22        93 438930000       0.05080\npolygon 23        87 274127000       0.03170\npolygon 24       105 509979000       0.05910\npolygon 25        98 292058000       0.03380\npolygon 26        64 327765000       0.03800\npolygon 27       133 108945000       0.01260\npolygon 28       122 462169000       0.05350\npolygon 29        94 109715000       0.01270\npolygon 30        95  61239800       0.00709\nenclosing rectangle: [176503.22, 291043.82] x [331434.7, 454520.1] units\n                     (114500 x 123100 units)\nWindow area = 8635910000 square units\nFraction of frame area: 0.613\n\nplot(funcppp1)\n\n\n\n#nonfuncppp\nnonfuncppp1<-nonfuncppp[NGA_owin]\nsummary(nonfuncppp1)\n\nPlanar point pattern:  2059 points\nAverage intensity 2.384232e-07 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: polygonal boundary\n30 separate polygons (no holes)\n            vertices      area relative.area\npolygon 1        204 766084000       0.08870\npolygon 2         81 304399000       0.03520\npolygon 3         97 465688000       0.05390\npolygon 4        124 373051000       0.04320\npolygon 5         60 149473000       0.01730\npolygon 6         84 144820000       0.01680\npolygon 7         50 102243000       0.01180\npolygon 8         72 216002000       0.02500\npolygon 9        112 269897000       0.03130\npolygon 10       125 365142000       0.04230\npolygon 11        83 111191000       0.01290\npolygon 12       126 192557000       0.02230\npolygon 13       219 904397000       0.10500\npolygon 14       174 741131000       0.08580\npolygon 15        81 138742000       0.01610\npolygon 16        65 119452000       0.01380\npolygon 17        90 280205000       0.03240\npolygon 18        69  69814600       0.00808\npolygon 19        69  42727500       0.00495\npolygon 20        49  30458800       0.00353\npolygon 21        62 263505000       0.03050\npolygon 22        93 438930000       0.05080\npolygon 23        87 274127000       0.03170\npolygon 24       105 509979000       0.05910\npolygon 25        98 292058000       0.03380\npolygon 26        64 327765000       0.03800\npolygon 27       133 108945000       0.01260\npolygon 28       122 462169000       0.05350\npolygon 29        94 109715000       0.01270\npolygon 30        95  61239800       0.00709\nenclosing rectangle: [176503.22, 291043.82] x [331434.7, 454520.1] units\n                     (114500 x 123100 units)\nWindow area = 8635910000 square units\nFraction of frame area: 0.613\n\nplot(nonfuncppp1)\n\n\n\n\n\n\n2.2.7 Rescale ppp data into km\nIn the code chunk below, rescale() is used to convert the unit of measurement from meter to kilometer\n\nfuncppp1.km<-rescale(funcppp1, 1000, \"km\")\nnonfuncppp1.km<-rescale(nonfuncppp1, 1000, \"km\")\n\nWith our data cleaned and in thr right format, we can move on to compute the Kernel Density Estimation!"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#first-order-spatial-point-pattern-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#first-order-spatial-point-pattern-analysis",
    "title": "Take-home Exercise 1",
    "section": "2.3 First-order Spatial Point Pattern Analysis",
    "text": "2.3 First-order Spatial Point Pattern Analysis\n\n2.3.1 Computing kernel density Estimation using adaptive bandwidth selection method\nIn spatial analysis, the choice of bandwidth is important for determining the smoothness of a surface fit to the data. The bandwidth determines the width of the smoothing kernel used in spatial smoothing techniques like kernel density estimation or local regression. We compare between two types of bandwidth methods, fixed and adaptive bandwidth, to be applied to this situation.\nFixed bandwidth methods use a constant value for the bandwidth throughout the analysis, regardless of the distribution of the data. This can be useful when the data has a consistent structure, but if the data is highly variable or has multiple modes, a constant bandwidth may not provide an adequate fit to the data.\nAdaptive bandwidth methods, on the other hand, use a variable bandwidth that adjusts based on the local structure of the data. This allows for more flexibility in the fitting process.\nFrom our initial plots, we can see that there is some evidence of clustering, leading to our choice of using adaptive bandwidth in our analysis.\n\nfunckde_adaptive<- adaptive.density(funcppp1.km, method=\"kernel\")\n\nnonfunckde_adaptive<- adaptive.density(nonfuncppp1.km, method=\"kernel\")\n\npar(mfrow=c(1,2))\nplot(funckde_adaptive, main=\"Functional Waterpoint KDE using Adaptive Bandwidth\")\nplot(nonfunckde_adaptive, main=\"Non-Functional Waterpoint KDE using Adaptive Bandwidth\")\n\n\n\n\n\n\n2.3.2 Convert KDE into grid object\nConverting KDE into a gridded object that is suitable for mapping purposes.\n\ngridded_kde_funckde <- as.SpatialGridDataFrame.im(funckde_adaptive)\n\ngridded_kde_nonfunckde <- as.SpatialGridDataFrame.im(nonfunckde_adaptive)\n\n\n\n2.3.3 Convert gridded output into raster\nNext we convert the gridded kernal density objects into RasterLayer objet using raster() of raster package.\n\nfunckde_raster<-raster(gridded_kde_funckde)\nfunckde_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : 1.320603e-16, 23.9989  (min, max)\n\nnonfunckde_raster<-raster(gridded_kde_nonfunckde)\nnonfunckde_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : 6.85125e-17, 20.92404  (min, max)\n\n\nNotice that the crs is NA\n\n\n2.3.4 Assigning Projection Systems\nThe code chunk below is used to include the CRS information funckde_raster and nonfunckde_raster.\n\nprojection(funckde_raster) <- CRS(\"+init=EPSG:26392 +units=km\")\nfunckde_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +units=km +no_defs \nsource     : memory\nnames      : v \nvalues     : 1.320603e-16, 23.9989  (min, max)\n\nres(funckde_raster)\n\n[1] 0.8948485 0.9616045\n\nprojection(nonfunckde_raster) <- CRS(\"+init=EPSG:26392 +units=km\")\nnonfunckde_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +units=km +no_defs \nsource     : memory\nnames      : v \nvalues     : 6.85125e-17, 20.92404  (min, max)\n\nres(nonfunckde_raster)\n\n[1] 0.8948485 0.9616045\n\n\n\n\n2.3.5 Viewing object in tmap\nFinally, we will display the raster in cartographic quality map using tmap package.\n\ntmap_mode(\"view\")\ntm_basemap(server =\"OpenStreetMap\")+ \ntm_shape(funckde_raster) + \n  tm_raster(\"v\") +\n  tm_layout(main.title = \"Raster Plot of Functional Waterpoint KDE\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE)\n\n\n\n\ntmap_mode(\"view\")\ntm_basemap(server =\"OpenStreetMap\")+ \ntm_shape(nonfunckde_raster) + \n  tm_raster(\"v\") +\n  tm_layout(main.title = \"Raster Plot of Non-Functional Waterpoint KDE\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE)\n\n\n\n\n\nChange tmap mode to plot.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#second-order-spatial-point-patterns-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#second-order-spatial-point-patterns-analysis",
    "title": "Take-home Exercise 1",
    "section": "9 Second-order Spatial Point Patterns Analysis",
    "text": "9 Second-order Spatial Point Patterns Analysis\nFor the purposes of Spatial Point Analysis, we are attempting to determine a pattern in terms of either clustering or standardization of point spread. However, in order to do so, we must first reject the null hypothesis that they are randomly distributed to arrive at any conclusion. Thus:\nThe test hypotheses are:\n\nHo = The distribution of Functional/Non Functional Waterpoints are randomly distributed.\nH 1= The distribution of Functional/Non Functional Waterpoints services are not randomly distributed.\n\nWe will set a 95% confidence interval for the purpose of this study.\n\n9.1 Analysing Spatial Point Process Using G-Function\n\nG_Fun = Gest(funcppp1, correction = \"border\")\nplot(G_Fun, xlim=c(0,500))\n\n\n\n\n\nGenerating Mote Carlo test with G-Function\n\n\nG_Fun.csr <- envelope(funcppp1, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot\n\n\nplot(G_Fun.csr)\n\n\n\nsummary(G_Fun.csr)\n\nPointwise critical envelopes for G(r)\nand observed value for 'funcppp1'\nObtained from 999 simulations of CSR\nAlternative: two.sided\nUpper envelope: pointwise maximum of simulated curves\nLower envelope: pointwise minimum of simulated curves\nSignificance level of Monte Carlo test: 2/1000 = 0.002\nData: funcppp1\n\n\n\nComputing F-function estimate\n\n\nF_Fun = Fest(funcppp1)\nplot(F_Fun, xlim=c(0,500))\n\n\n\n\n\nGenerating Mote Carlo test with G-Function\n\n\nF_Fun.csr <- envelope(funcppp1, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot\n\n\nplot(F_Fun.csr)\n\n\n\nsummary(F_Fun.csr)\n\nPointwise critical envelopes for F(r)\nand observed value for 'funcppp1'\nObtained from 999 simulations of CSR\nAlternative: two.sided\nUpper envelope: pointwise maximum of simulated curves\nLower envelope: pointwise minimum of simulated curves\nSignificance level of Monte Carlo test: 2/1000 = 0.002\nData: funcppp1\n\n\nConclusion: it is clustered."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-chi-squared-test",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-chi-squared-test",
    "title": "Take-home Exercise 1",
    "section": "10 Performing Chi-squared test",
    "text": "10 Performing Chi-squared test\n\nquadrat_t <- quadrat.test(funcppp1, \n                   nx = 15, ny = 15)\n\n\nplot(funcppp1)\nplot(quadrat_t, add = TRUE, cex =.1)\n\n\n\n\n\n10.1 Interpretation of Chi-Square test\nBased on our hypothesis and confidence level specified, we reject the null hypothesis at a 95% confidence level. This is due to our extremely low p-value of 2.2e-16."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-clark-evans-test",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-clark-evans-test",
    "title": "Take-home Exercise 1",
    "section": "11 Performing Clark-Evans test",
    "text": "11 Performing Clark-Evans test\n\nclarkevans.test(funcppp1,\n                correction=\"none\",\n                clipregion=\"NGA_owin\",\n                alternative=c(\"two.sided\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  funcppp1\nR = 0.44225, p-value = 0.02\nalternative hypothesis: two-sided\n\n\n\n11.1 Interpretation of the Clark-Evans test\nBased on the clark evans test with 99 simulations, we are able to reject the null hypothesis at a 95% confidence level with a p-value of 0.02. Additionally, with an index of 0.33359 which is less than 1, there is indication of clustering."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#advanced-spatial-point-pattern-analysis-colocation-coefficient",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#advanced-spatial-point-pattern-analysis-colocation-coefficient",
    "title": "Take-home Exercise 1",
    "section": "6 Advanced Spatial Point Pattern Analysis-Colocation Coefficient",
    "text": "6 Advanced Spatial Point Pattern Analysis-Colocation Coefficient\nVisualising the sf layers\n\ntmap_mode(\"view\")\ntm_shape(bd)+\n  tm_polygons()+\n  tm_shape(wp_sf_nga)+\n  tm_dots(col=\"status_clean\")\n\n\n\n\n\n#streamlining data into functional and non-functional waterpoints only\nnonfunc_df<-wp_sf_nga |> \nfilter(status_clean %in% \n           c(\"Abandoned/Decommissioned\",\n             \"Abandoned\",\n             \"Non-Functional due to dry season\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\")) |> \n  mutate(status_redefined=\"Non-functional\")\n\nfunc_df<-wp_sf_nga |> \nfilter(status_clean %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\")) |> \n  mutate(status_redefined=\"Functional\")\n\n#combining data frames into 1 df\ndf<-bind_rows(func_df, nonfunc_df)\n\n#plotting the combined dataframe\ntmap_mode(\"view\")\ntm_shape(bd)+\n  tm_polygons()+\n  tm_shape(df)+\n  tm_dots(col=\"status_redefined\",\n          size=0.01,\n          border.col=\"black\",\n           border.lwd=0.5)\n\n\n\n\n\n\n\n6.1 Local Colocation coefficient\n\nnb<-include_self(\n  st_knn(st_geometry(df), 6)\n)\n\nwt<-st_kernel_weights(nb,\n                      df,\n                      \"gaussian\",\n                      adaptive=TRUE) \n\n\nFW<-df |> \n  filter(status_redefined == \"Functional\")\nA<- FW$status_redefined\n\nNFW<-df |> \n  filter(status_redefined == \"Non-functional\")\nB<- NFW$status_redefined\n\nLCLQ<-local_colocation(A, B, nb, wt, 49)\n\nLCLQ_WP<-cbind(df,LCLQ)\n\n#plot the graph\ntmap_mode(\"view\")\ntm_shape(bd) +\n  tm_polygons() + \ntm_shape(LCLQ_WP) +\n  tm_dots(col=\"Non.functional\")+\n  tm_view(set.zoom.limits = c(9,13))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-conversion-from-sf-to-ppp",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-conversion-from-sf-to-ppp",
    "title": "Take-home Exercise 1",
    "section": "2.1 Data conversion from sf to ppp",
    "text": "2.1 Data conversion from sf to ppp\n\n2.1.1 Converting water point data into sf point features\nFirst we need to convert the wkt field into sfc field by using st_as_sfc() data type. Next we will convert the tibble data.frame into an sf object by isomh st_sf(). it is also important for us to include the referencing system of the data into the sf object. In this case, it has the CRS of WGS 84, so we set the crs to EPSG code 4326.\n\nwp_osun$Geometry = st_as_sfc(wp_osun$`New Georeferenced Column`)\nwp_osun\n\n# A tibble: 5,557 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429123 GRID3             8.02    5.06 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2  70566 Federal Minis…    7.32    4.79 05/11/… No      Protec… Well    Mechan…\n 3  70578 Federal Minis…    7.76    4.56 05/11/… No      Boreho… Well    Mechan…\n 4  66401 Federal Minis…    8.03    4.64 04/30/… No      Boreho… Well    Mechan…\n 5 422190 GRID3             7.87    4.88 08/29/… Unknown <NA>    <NA>    Tapsta…\n 6 422064 GRID3             7.7     4.89 08/29/… Unknown <NA>    <NA>    Tapsta…\n 7  65607 Federal Minis…    7.89    4.71 05/12/… No      Boreho… Well    Mechan…\n 8  68989 Federal Minis…    7.51    4.27 05/07/… No      Boreho… Well    <NA>   \n 9  67708 Federal Minis…    7.48    4.35 04/29/… Yes     Boreho… Well    Mechan…\n10  66419 Federal Minis…    7.63    4.50 05/08/… Yes     Boreho… Well    Hand P…\n# … with 5,547 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\nwp_sf <-  st_sf(wp_osun, crs=4326) #convert to sf, tell R what crs used for projection \nwp_sf\n\nSimple feature collection with 5557 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 4.032004 ymin: 7.060309 xmax: 5.06 ymax: 8.061898\nGeodetic CRS:  WGS 84\n# A tibble: 5,557 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429123 GRID3             8.02    5.06 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2  70566 Federal Minis…    7.32    4.79 05/11/… No      Protec… Well    Mechan…\n 3  70578 Federal Minis…    7.76    4.56 05/11/… No      Boreho… Well    Mechan…\n 4  66401 Federal Minis…    8.03    4.64 04/30/… No      Boreho… Well    Mechan…\n 5 422190 GRID3             7.87    4.88 08/29/… Unknown <NA>    <NA>    Tapsta…\n 6 422064 GRID3             7.7     4.89 08/29/… Unknown <NA>    <NA>    Tapsta…\n 7  65607 Federal Minis…    7.89    4.71 05/12/… No      Boreho… Well    Mechan…\n 8  68989 Federal Minis…    7.51    4.27 05/07/… No      Boreho… Well    <NA>   \n 9  67708 Federal Minis…    7.48    4.35 04/29/… Yes     Boreho… Well    Mechan…\n10  66419 Federal Minis…    7.63    4.50 05/08/… Yes     Boreho… Well    Hand P…\n# … with 5,547 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\nHowever, we want to convert the coordinate reference system to Nigeria’s projected coordinate system. We use st_transform(), and include the EPSG code for Nigeria’s projected coordinate system: 26392.\n\nwp_sf <- wp_sf %>%\n  st_transform(crs = 26392)\n\nqtm(wp_sf) #quick view\n\n\n\n\n\n\n2.1.2 Data wrangling for waterpoint data\nIn cleaning the waterpoint data, we first rename the column from #status_clean to status_clean for easier handling in subsequent steps. select() of dplyr is used to include status_clean in the output sf data.frame. - mutate() and replace_na() are used to recode all the NA values in status_clean into unknown.\n\nwp_sf_nga <- wp_sf |> \n  rename(status_clean = '#status_clean') |> \n  select(status_clean) |> \n  mutate(status_clean = replace_na(\n    status_clean, \"unknown\"\n  ))\n\n\n\n2.1.3 Extracting water point data\nNow we are ready to extract the water point data according to their status.\nThe code chunk below is used to extract functional water points.\n\nwp_functional <- wp_sf_nga |> \n  filter(status_clean %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\nThe code chunk below is used to extract nonfunctional waterpoint.\n\nwp_nonfunctional <- wp_sf_nga |> \n  filter(status_clean %in% \n           c(\"Abandoned/Decommissioned\",\n             \"Abandoned\",\n             \"Non-Functional due to dry season\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\"))\n\nThe code chunk below is used to extract water point with unknown status.\n\nwp_unknown <- wp_sf_nga |> \n  filter(status_clean %in% \n           c(\"unknown\"))\n\nNext, the code chunk below is used to perform a quick EDA on the derived sf data.frames.\n\nfreq(data = wp_functional,\n     input = 'status_clean')\n\n\n\n\n                 status_clean frequency percentage cumulative_perc\n1                  Functional      2319      88.17           88.17\n2 Functional but needs repair       248       9.43           97.60\n3   Functional but not in use        63       2.40          100.00\n\n\n\nfreq(data = wp_nonfunctional,\n     input = 'status_clean')\n\n\n\n\n                      status_clean frequency percentage cumulative_perc\n1                   Non-Functional      2008      92.15           92.15\n2 Non-Functional due to dry season       151       6.93           99.08\n3                        Abandoned        15       0.69           99.77\n4         Abandoned/Decommissioned         5       0.23          100.00"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "title": "Take-home Exercise 1",
    "section": "4.1 Data Wrangling",
    "text": "4.1 Data Wrangling\nWe first start with a plot of the distribution of the waterpoints using wp_sf_nga and bd objects defined earlier.\n\ntmap_mode(\"view\")\ntm_shape(bd)+\n  tm_polygons()+\n  tm_shape(wp_sf_nga)+\n  tm_dots(col=\"status_clean\")\n\n\n\n\n\n#streamlining data into functional and non-functional waterpoints only\n\nWe realise that under the column “status_clean”, there are too many categories, which can be difficult for interpretation especially when we want to calculate colocation quotients. We will conduct data wrangling in the next step to define the waterpoints distinctly into “functional” and “non-functional”.\n\nnonfunc_df<-wp_sf_nga |> \nfilter(status_clean %in% \n           c(\"Abandoned/Decommissioned\",\n             \"Abandoned\",\n             \"Non-Functional due to dry season\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\")) |> \n  mutate(status_redefined=\"Non-functional\")\n\nfunc_df<-wp_sf_nga |> \nfilter(status_clean %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\")) |> \n  mutate(status_redefined=\"Functional\")\n\n#creating a status_redefined column that states if water point is either functional or non functional\n\ndf<-bind_rows(func_df, nonfunc_df) |> \n  mutate(status_redefined=factor(status_redefined)) |> \n  select(Geometry, status_redefined)\n#combining data frames into 1 df\n\nWith our new dataframe, we continue to plot a graph showing the the functional and non-functional water points using tmap.\n\ntmap_mode(\"view\")\ntm_shape(bd)+\n  tm_polygons()+\n  tm_shape(df)+\n  tm_dots(col=\"status_redefined\",\n          size=0.01,\n          border.col=\"black\",\n           border.lwd=0.5)\n\n\n\n\n\n#plotting the combined dataframe"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#local-colocation-coefficient",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#local-colocation-coefficient",
    "title": "Take-home Exercise 1",
    "section": "4.2 Local Colocation coefficient",
    "text": "4.2 Local Colocation coefficient\nAccording to this website, the colocation analysis tool measures local patterns of spatial association between two categories of point features using the colocation quotient statistic.\nEach feature in the Category of Interest (category A) is evaluated individually for colocation with the presence of the Neighboring Category (category B) found within its neighborhood. In general, if the proportion of B points within the neighborhood of A is more than the global proportion of B, the colocation quotient will be high. If the neighborhood of A contains many other A points or many other categories other than B, the colocation between the Category of Interest (category A) and the Neighboring Category (category B) will be small.\nIn our analysis, our category of interest (A) is functional waterpoints, and neighboring category (B) is non-functional waterpoints.\n\n4.2.1 Preparing the vector list\n\nFW<-df |> \n  filter(status_redefined == \"Functional\")\nA<- FW$status_redefined\n\nNFW<-df |> \n  filter(status_redefined == \"Non-functional\")\nB<- NFW$status_redefined\n\n\n\n4.2.2 Preparing nearest neighbour list\nIn the code chunk below, st_knn() of sfdep package is used to determine the k (i.e. 6) nearest neighbours for given point geometry.\n\nnb<-include_self(\n  st_knn(st_geometry(df), 6)\n)\n\n\n\n4.2.3 Computing Kernel Weights\nIn the code chunk below, st_kernel_weights() of sfdep package is used to derive a weights list by using a kernel function.\n\nwt<-st_kernel_weights(nb,\n                      df,\n                      \"gaussian\",\n                      adaptive=TRUE)\n\n\n\n4.2.4 Computing LCLQ\nIn the code chunk below local_colocation() us used to compute the LCLQ values for each Water point event.\n\nLCLQ<-local_colocation(A, B, nb, wt, 39)\n\n\n\n4.2.5 Joining output Table\nBefore we can plot the LCLQ values their p-values, we need to join the output of local_colocation() to the stores sf data.frame. However, a quick check of LCLQ data-frame, we can’t find any field can be used as the join field. As a result, cbind() of Base R is useed.\n\nLCLQ_WP<-cbind(df,LCLQ)\n\n\n\n4.2.6 Plotting LCLQ values\nIn the code chunk below, tmap functions are used to plot the LCLQ analysis.\n\n#plot the graph\ntmap_mode(\"view\")\ntm_shape(bd) +\n  tm_polygons() + \ntm_shape(LCLQ_WP) +\n  tm_dots(col=\"Non.functional\")+\n  tm_view(set.zoom.limits = c(9,13))+\ntm_shape(LCLQ_WP) +\n  tm_dots(col=\"p_sim_Non.functional\")+\n  tm_view(set.zoom.limits = c(9,13))\n\n\n\n\n\n\n\n\n4.2.7 Statistical conclusion\nFrom the statistical table, we see that the colocation coefficient is less than 1 but extremely close to one for some points.\nFrom this website, features that have colocation quotients less than one are less likely to have category B within their neighborhood. If a feature has a colocation quotient equal to one, it means the proportion of categories within their neighborhood is a good representation of the proportion of categories throughout the entire study area.\nTherefore, it is likely that there is some correlation between location of functional and non functional water points. Additionally given that the p-value is less than 0.05 for the selected points, we can say that the result is statistically significant, and that Functional and non-functional water points are dependent with each other.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-appropriate-tests-using-second-order-spatial-point-pattern-analysis-technique",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-appropriate-tests-using-second-order-spatial-point-pattern-analysis-technique",
    "title": "Take-home Exercise 1",
    "section": "4.3 Performing appropriate tests using second order spatial point pattern analysis technique",
    "text": "4.3 Performing appropriate tests using second order spatial point pattern analysis technique\nWe will use the Cross-K Function to look into this relationship\nThe test hypotheses are:\n\nHo = The distribution of functional and non-functional waterpoints are spatially independent from each other (ie randomly distributed).\nH 1= The ditribution of functional and non-functional waterpoints are not independent from each other (ie not randomly distributed).\n\nWe will set a 95% confidence interval for the purpose of this study.\n\n4.3.1 Conversion of LCLQ data into ppp\nIn this analysis, we seek to perform marked point pattern analysis, based on the associated categorical measurement “status_redefined” in the waterpoint data.\n\ndf_spatialpoint<-df |>\n  as(\"Spatial\") |> \n  as(\"SpatialPointsDataFrame\") #creating spatial point data frame from sf\n\ndf_spatialpoint@data$status_redefined<-as.factor(df_spatialpoint@data$status_redefined) #creating a factor column for status_redefined\n\ndf_ppp<-df_spatialpoint |> \n  as(\"ppp\") #converting the spatial data frame into a ppp object\n\ndf_ppp_owin<-df_ppp[NGA_owin] #creating an owin object\n\nplot(df_ppp_owin, main = \"df_ppp\", which.marks = \"status_redefined\") #creating a quick plot to visualise the ppp object\n\n\n\n\n\n\n4.3.2 Using Cross K function to check for distribution trend\nWe use the cross-K function to analyse the trend of distribution of both functional and non-functional waterpoints.\n\nLcross.csr <- envelope(df_ppp_owin, \n                                 Lcross, \n                                 i=\"Functional\", \n                                 j=\"Non-functional\", \n                                 correction=\"border\", \n                                 nsim=39)\n\nGenerating 39 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,  39.\n\nDone.\n\n\nWe can then plot our result\n\nplot(Lcross.csr, \n     xlim = c(0,10000))\n\n\n\n\n\n\n4.3.3 Statistical conclusions\nFrom the graph above, we can conclude that there is evidence of spatial dependence between 0 to 5000, and 7000 to 8000 r values. More specifically, between 0 to 5000, functional and non-functional waterpoints tend to cluster, while between 7000 to 8000, they tend to be evenly distributed."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-data",
    "title": "Take-home Exercise 1",
    "section": "5.1 Importing data",
    "text": "5.1 Importing data\nIn researching for population data for Osun state, we chose to use population density from this website.\nWe save the webpage as a html file, and open it using microsoft excel, to generate the table in xls format. Subsequently, we save the excel file into csv format for analysis in R. The file will be saved with the name “pop_data_nga.csv”.\n\npop_data<-read.csv(\"data/pop_data_nga.csv\")\n\nosun_pop <- pop_data %>% \n  rename(shapeName = `Local.gov..area.`, \n         HASC = `HASC....`,\n         Capital = `Capital.....`, \n         Population = `Population....`,\n         State = `State....`) |> \n  filter(State == \"Osun\")\n\nTo plot the population data, we use ADM2 data which defines the specific geoboundaries of LGAs in states.\n\n#Joining data from both data frames, preserving sf  properties\ngeoNGA2_osun<-bd |> \n  left_join(osun_pop, by=c(\"ADM2_EN\"=\"shapeName\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#plotting-waterpoint-data-and-population-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#plotting-waterpoint-data-and-population-data",
    "title": "Take-home Exercise 1",
    "section": "5.2 Plotting waterpoint data and population data",
    "text": "5.2 Plotting waterpoint data and population data\nWith our data ready, we can plot the projected population using tmap functions.\n\ntm_shape(geoNGA2_osun)+\n  tm_fill(\"Density\",\n          style = \"quantile\", \n          palette = \"-Blues\",\n          title = \"Population Density of Osun LGAs\")+\n  tm_layout(main.title = \"Population Density of Osun LGAs\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)+\n  tm_shape(filter(df,status_redefined==\"Functional\"))+\n  tm_dots(col=\"green\",\n          size=0.01,\n          border.col=\"black\",\n           border.lwd=0.5,\n          alpha=0.5)+\n  tm_shape(filter(df,status_redefined==\"Non-functional\"))+\n  tm_dots(col=\"red\",\n          size=0.01,\n          border.col=\"black\",\n           border.lwd=0.5,\n          alpha=0.5)\n\n\n\n\nChange tmap_mode to plot\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conclusions",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#conclusions",
    "title": "Take-home Exercise 1",
    "section": "5.3 Conclusions",
    "text": "5.3 Conclusions\nFrom the plot, we see that high population density areas such as Ife Central, Ede North, Boripe, Ilesha West and Orolu have high coincidence of non-functional waterpoints. This could possibly imply the overuse of waterpoints by the larger population. More importantly, this finding can be used by government agencies who are pioritising repair schedules for the non-functional waterpoints."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class_Ex06",
    "section": "",
    "text": "pacman::p_load(sf, sfdep, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#the-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#the-data",
    "title": "In-class_Ex06",
    "section": "The data",
    "text": "The data"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "Two data sets will be used in this hands-on exercise, they are:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-started",
    "title": "Hands-on_Ex04",
    "section": "Getting Started",
    "text": "Getting Started\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\nImport Shapefile into R environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/pengyouyun/youyunpeng/IS415/Hands-on_Ex/Hands-on_Ex04/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nImport csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nPerforming relational join\nThe code chunk below will be used to update the attribute table of hunan's SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan <- left_join(hunan,hunan2012)%>%\n  select(1:4, 7, 15)\n\nJoining, by = \"County\""
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-regional-development-indicator",
    "title": "Hands-on_Ex04",
    "section": "Visualising Regional Development Indicator",
    "text": "Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nbasemap <- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc <- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-contiguity-spatial-weights",
    "title": "Hands-on_Ex04",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\nIn this section, you will learn how to use poly2nb() of spdep package to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a \"queen\" argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don't specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\nComputing (QUEEN) contiguity based neighbours\nThe code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q <- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below.\n\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen's method are 20981, 34592, 24473, 21311 and 22879 respectively.\nYou can display the complete weight matrix by using str().\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\nCreating (ROOK) contiguity based neighbours\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r <- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connect area unit has 10 neighbours. There are two area units with only one heighbours.\n\n\nVisualising Contiguity weights\nA connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs. Getting Latitude and Longitude of Polygon Centroids\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords <- cbind(longitude, latitude)\n\nWe check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\nPlotting Queen contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\nPlotting Rook Contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\nPlotting both Queen and Rook contiguity based neighbours maps\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\", main=\"Queen Contiguity\")\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\", main=\"Rook Contiguity\")"
  }
]